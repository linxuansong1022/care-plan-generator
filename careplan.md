# careplan课程 - 2sum

> ⚠️ 版权声明
> 
> 
> 本课程由 **2SumTech LLC** 出品，版权所有。
> 
> **禁止私自传播、转载、复制或用于商业用途。违者将追究法律责任。**
> 
> 小红书：2sum
> 

# 通知

**通知1: 微信：twosumtech, 需要联系我，给我你的email，然后我给你github invitation** 

**通知2：我把天数分成不同的chapter了，内容没变，格式变了：**

**[](https://www.notion.so/e9073b2e0063830482a8017a13a2a10f?pvs=21) 因为大家普遍喜欢这种分天的格式，之后我会再这个里面更新，本文档就不再更新了。**

**通知3:** 非常推荐付费claude一个月会员，20刀，我自己是100刀用户，但是学生20刀就够用了。加上4.6 非常好用。

![Screenshot 2026-02-05 at 7.11.46 PM.png](careplan%E8%AF%BE%E7%A8%8B%20-%202sum/Screenshot_2026-02-05_at_7.11.46_PM.png)

# 页面快速使用方式

如果喜欢当前这个页面的排版，这里可以快速access

![Screenshot 2026-02-05 at 10.44.31 AM.png](careplan%E8%AF%BE%E7%A8%8B%20-%202sum/Screenshot_2026-02-05_at_10.44.31_AM.png)

![Screenshot 2026-02-05 at 10.45.51 AM.png](careplan%E8%AF%BE%E7%A8%8B%20-%202sum/Screenshot_2026-02-05_at_10.45.51_AM.png)

# 目录

## 课程说明

本课程带你完成一个真实的企业级项目，从需求分析到部署上线。本课程不是一次性设计好再实现，而是像真实项目一样迭代开发：

每一天都在解决上一天遇到的问题。这样你会真正体验到”为什么需要这个技术”，而不是死记硬背。

注意千万不要一下让AI把内容给你,因为我故意设计的是每一个步骤都有一点小缺陷,而这个缺陷正好就是你第二天会学习的内容。

如果你没有体会这个缺陷,而直接把这个东西给实现出来的话,你会意识不到每个东西具体负责的内容是什么，或者你会不知道某一个实现的内容到底是由哪个技术实现的。

所以核心是：每一天都在解决前一天遇到的问题。

**计算机不难，我们不是想不到解决思路，我们只是没有踩坑的过程，但凡让我们踩个坑，所有的解决方案我们都能想到。**

## 完成后你将实现

一个**完整的医疗 Care Plan 生成系统**：

**功能：**
- ✅ 用户通过 Web 表单输入患者信息、药物、诊断
- ✅ 系统自动检测重复患者和重复订单
- ✅ 调用 LLM 自动生成专业的 Care Plan
- ✅ 用户可以下载 Care Plan 文件
- ✅ 支持数据导出用于报告
- ✅ 支持接收不同来源的订单数据

**技术能力：**
- ✅ 设计异步架构处理耗时任务
- ✅ 实现复杂的业务验证逻辑
- ✅ 使用Adapter模式处理多数据源
- ✅ 使用 Docker 容器化开发和部署
- ✅ 使用 Terraform 部署到 AWS
- ✅ 配置 Prometheus + Grafana 监控

**面试能力：**
- ✅ 能解释架构设计的权衡
- ✅ 能回答 LLM 调用失败怎么办
- ✅ 能说清楚重复检测的业务逻辑
- ✅ 能写出好的 AI Prompt

---

## 我们会一点点涉及到的技术栈

| 类别 | 技术 | 用途 |
| --- | --- | --- |
| **后端** | Python, Django, Django REST Framework | Web 框架、API 开发 |
| **前端** | React, JavaScript | 用户界面 |
| **数据库** | PostgreSQL | 数据存储 |
| **异步任务（本地）** | Celery, Redis | 本地开发的后台任务 |
| **异步任务（AWS）** | SQS, Lambda | 生产环境的后台任务 |
| **AI/LLM** | Claude API 或 OpenAI API | Care Plan 生成 |
| **容器化** | Docker, Docker Compose | 本地开发 + 部署 |
| **云部署** | AWS (EC2, Lambda, RDS, SQS, S3) | 生产环境 |
| **基础设施** | Terraform | 基础设施即代码 |
| **监控** | Prometheus, Grafana | 指标收集、可视化 |
| **测试** | pytest | 单元测试、集成测试 |

# Day 1: 需求分析 + 客户沟通

> 🎯 面试考点
> 
> 
> 很多候选人拿到需求就开始写代码，这是**最常见的错误**。我自己面试的时候，我会非常注意这一点。之前面试官也无数次跟我说过，很多人不会做这一步，直接做的话已经被fail掉了。
> 

---

to export for reporting to pharma

**Production-Ready requirements:**
- Every input is validated
- Integrity rules always enforce consistency
- Errors are safe, clear, and contained
- Code is modular and navigable
- Critical logic is covered by automated tests
- Project runs end-to-end out of the box

---

### 示例数据

**输入示例：患者记录**

```
Name: A.B. (Fictional)
MRN: 00012345 (fictional)
DOB: 1979-06-08 (Age 46)
Sex: Female
Weight: 72 kg
Allergies: None known to medications (no IgA deficiency)
Medication: IVIG

Primary diagnosis: Generalized myasthenia gravis (AChR antibody positive), MGFA class IIb
Secondary diagnoses: Hypertension (well controlled), GERD

Home meds:
- Pyridostigmine 60 mg PO q6h PRN
- Prednisone 10 mg PO daily
- Lisinopril 10 mg PO daily
- Omeprazole 20 mg PO daily

Recent history:
Progressive proximal muscle weakness and ptosis over 2 weeks...
Neurology recommends IVIG for rapid symptomatic control...
```

**输出示例：Care Plan**

```
Problem list / Drug therapy problems (DTPs)
- Need for rapid immunomodulation to reduce myasthenic symptoms
- Risk of infusion-related reactions
- Risk of renal dysfunction or volume overload
- Risk of thromboembolic events
- Potential drug–drug interactions
- Patient education / adherence gap

Goals (SMART)
- Primary: Achieve clinically meaningful improvement in muscle strength within 2 weeks
- Safety goal: No severe infusion reaction, no acute kidney injury
- Process: Complete full 2 g/kg course with documented monitoring

Pharmacist interventions / plan
- Dosing & Administration
- Premedication
- Infusion rates & titration
- Hydration & renal protection
- Monitoring during infusion
- Adverse event management

Monitoring plan & lab schedule
- Before first infusion: CBC, BMP, baseline vitals
- During each infusion: Vitals q15–30 min
- Post-course (3–7 days): BMP to check renal function
```

---

## ⚠️ 停！在继续之前请先阅读这里

**你现在是不是想把上面的需求复制粘贴给 AI，让它帮你直接开始写代码了？**

很多人会这样做：

```
这是我的需求：[粘贴需求]
请帮我用 Django 实现这个系统。
```

这样做 AI 确实会给你生成一堆代码。但问题是：
1. **需求本身有很多模糊的地方**，AI 会自己”脑补”，可能和客户想要的不一样
2. **你不理解为什么这样设计**，面试时解释不清楚
3. **生成的代码结构可能很乱**，因为 AI 不知道哪些是重点

**真正的考点是：需求澄清。**

> 🎯 面试官想看到的是：你拿到需求后，先问问题，而不是直接开始写代码。
> 

---

**⚠️ 重要：如何正确使用 AI**

我们必须明白一件事：**AI 是工具，工具是不能思考的，工具是被人使用的。**

就像有的人用木头能盖出房子，有的人用木头能造出车子。你不能用工具取代你的思考。

**错误的做法：**
- 看到需求后，立刻复制粘贴给 AI，让 AI 帮你翻译
- 直接问 AI：“这是什么？帮我理解”
- 让 AI 帮你讲解每一章是什么意思

**为什么这样不行？** 因为你并没有带着问题去问 AI。你让 AI 帮你理解，但你都没有问题，你让它帮你理解啥呢？这也是面试中很多人没过的原因——太依赖 AI 了。

**正确的做法：**
1. 看到需求后，先**通篇 word by word 读下来**，大概花 5 分钟
2. 读完后你会有一些问题（业务逻辑上的、需求澄清上的）
3. **带着这些问题**去问 AI

**记住：先思考，再提问。**

## 1.2 思考练习：需求澄清

看完需求文档后，你发现哪些地方不够清晰？自己先想至少10分钟。

.

.

.

.

.

.

.

.

.

.

这些地方有想到吗? 
- “Warning if orders look like duplicates” — 什么算 duplicate？用户看到 warning 后能继续吗？
- “Provider only be entered once” — 如果 NPI 相同但名字不同怎么办？
- 哪些功能是必须的，哪些可以后面做？

在实际的工作中，我们还会问这些问题：

[项目规划讨论 Checklist - 面试准备](https://www.notion.so/Checklist-2f073b2e006381a2b088c993614f51e9?pvs=21)

---

### 🤖 你现在是不是又想问 AI 了？

```jsx
“这是文档，先帮我分析需求” 
```

这也不是一个好的 prompt。为什么？

因为 AI 不知道你想要什么：
- 是要帮你写代码？
- 是要帮你找 bug？## 1.1 原始需求文档

你收到了以下客户需求：

---

**Customer:** A specialty pharmacy

**Use Case:** We want to be able to automatically generate care plans based on information (clinicals) found within the patient’s record.

**Why this is urgent:** It takes our pharmacists 20-40 min per patient to put these together manually. We are required to do these for compliance reasons and to get reimbursed by Medicare and pharma. We are extremely short-staffed so are backlogged on this task.

**What we do today:** Our pharmacist will look at the patient’s medical history and generate a care plan. Here are the inputs we require:

- Patient First Name, string
- Patient Last Name, string
- Referring Provider, string
- Referring Provider NPI, 10-digit number
- Patient MRN (unique ID), unique 6 digit number
- Patient Primary Diagnosis (ICD-10 code)
- Medication Name, string
- Additional Diagnosis, list of ICD-10 codes
- Medication history, list of strings
- Patient Records, string OR pdf document

**What we need the tool to do:**
- Allow a medical assistant to input the above information in a webform
- The webform must validate the data above
- Warning if orders look like duplicates
- Warning if a patient looks like it is duplicated
- Provider only be entered once in the system
- Call an LLM to generate a care plan as a text file they can download
- Quick way 
- 还是要帮你列出需要问客户的问题？

这就是为什么很多人用 AI 生成的代码质量不行、结构混乱 — 因为 prompt 本身就很模糊，AI 只能猜你想要什么。

**✅ 好的 prompt：**

通用技巧：
1. 提供上下文：技术栈、业务背景
2. 明确输出格式：要代码、要解释、还是两者都要
3. 分步骤问：复杂问题拆成小问题
4. 追问：如果回答不满意，追问”为什么”或”还有其他方案吗”

**✅ 好的 prompt：**

```
我拿到了一个项目需求（见下方）。在开始开发之前，我需要和客户确认一些细节。

请帮我列出：
1. 需求中哪些地方描述不够清晰？
2. 有哪些边界情况没有说明？
3. 我应该问客户哪些具体问题？

特别关注：
- 重复检测的具体逻辑（什么算重复？）
- 错误处理方式（warning vs error 的区别）
- 功能优先级

需求文档：
[粘贴需求]
```

**区别在哪？**
- 明确说了目的（和客户确认细节）
- 明确说了要什么输出（问题列表）
- 给了关注点（重复检测、错误处理）

---

## 1.3 你应该问客户的关键问题

> 我面了很多 AI startup，如果在面试的时候，这是一个非常大的考点，我希望你看完这个之后能明白要问哪些问题，并且把这个能力迁移到之后的面试里。
> 

### 检查你是否问了这些问题还是直接自己 assume 了：

1. Care plan 是按订单生成还是按患者生成？
2. Care plan 的输出格式有什么要求？必须包含哪些内容？
3. “订单重复” 的定义是什么？同一患者+同一药物就算重复吗？不同天呢？
4. “Warning” 的处理方式是什么？用户可以忽略继续吗？还是必须停止？
5. “患者重复” 的定义是什么？用什么字段判断？
6. Provider 重复怎么判断？如果 NPI 相同但名字不同呢？
7. 这个系统的用户是谁？是谁用？
8. 优先级相关，哪些功能是 Phase 1 必须有的？哪些可以后面做？

> 💡 为什么要问这些问题？
> 
> 
> 需求文档只说了 “warning if duplicates”，但没说：
> - 什么算重复？
> - warning 之后用户能继续吗？
> 
> 如果你不问，可能实现成”重复就阻止”，但客户想要”警告但允许继续”。
> 这就是**需求理解错误导致的返工**。
> 

---

## 1.4 为了确保结构一致 我们统一用以下需求

### 用户

是 CVS 的医疗工作者用，病人不接触这个系统。医疗工作者开药的时候需要一个 care plan，所以CVS 的医疗工作者会用，care plan 生成出来后他们会打印然后交给病人。

### Care Plan

- **一个 care plan 对应一个订单（一种药物）**
- 输出必须包含：Problem list, Goals, Pharmacist interventions, Monitoring plan

### 重复检测规则

| 场景 | 处理方式 | 原因 |
| --- | --- | --- |
| 同一患者 + 同一药物 + **同一天** | ❌ **ERROR** - 必须阻止 | 肯定是重复提交 |
| 同一患者 + 同一药物 + **不同天** | ⚠️ **WARNING** - 可以确认继续 | 可能是续方 |
| MRN 相同 + 名字或DOB不同 | ⚠️ **WARNING** - 可以确认继续 | 可能是录入错误 |
| 名字+DOB相同 + MRN不同 | ⚠️ **WARNING** - 可以确认继续 | 可能是同一人 |
| NPI 相同 + Provider名字不同 | ❌ **ERROR** - 必须修正 | NPI 是唯一标识 |

### 功能需求

| 功能 | 是否必须 | 说明 |
| --- | --- | --- |
| 患者/订单重复检测 | ✅ 必须 | 不能打乱现有工作流 |
| Care Plan 生成 | ✅ 必须 | 核心价值 |
| Provider 重复检测 | ✅ 必须 | 影响 pharma 报告 |
| 导出报告 | ✅ 必须 | pharma 报告需要 |
| Care Plan 下载 | ✅ 必须 | 用户需要上传到他们的系统 |

> 🎯 面试考点：你怎么和pm/ uiux designer 合作的？
用这个回答，平时开会的时候check这些东西：
> 
> 
> [Project Planning Checklist ](https://www.notion.so/Project-Planning-Checklist-2f073b2e006381778e00dfafec82493a?pvs=21)
> 

今天我们生成一个design doc 就行，关于这个design doc 里面具体写了啥不用在意，之后会改的，我只是想让你体验一下

1. 什么是desing doc, 长什么样，结构是什么
2. git的使用，把1.1 原始需求文档和1.4 复制粘体给ai，同时问：

```jsx
这是需求文档 先帮我总结一下成为一个design doc，生成为md文档。
```

## 1.5 先把项目放到 Git

**在开始写代码之前，先把项目放到 GitHub。**

为什么？

`代码有备份，不怕电脑坏了，每写完一点就提交，能跑了就提交，debug 不下去的时候可以回到之前能跑的版本`

在Cursor/ Codex里

**🤖 Prompt ：初始化 Git 并推到 GitHub**

```jsx
我要把项目放到 GitHub。

请告诉我：
1. 怎么在 GitHub 上创建一个新的 repository
2. 怎么在本地初始化 Git 并推送代码
3. 加上gitignore, 并解释gitignore 是干啥用的
4. 帮我加上之前生成的design doc
```

**Git 只需要记住三个命令：**

不需要记其他的Git的command了，面试的时候回答自己会用这三个就行了。

```jsx
git add .                    # 把所有改动加到暂存区
git commit -m "说明"          # 提交，写说明
git push                     # 推到 GitHub
```

**什么时候提交？代码能跑了就提交：**

```jsx
写完一个功能 → 测试能跑 → 立刻提交

git add .
git commit -m "能检测名字是否全是string了"
git push
```

**为什么要这样？**

你在加新功能，改了很多代码，改着改着，整个项目跑不起来了，debug 了两小时，越改越乱，最可气的是之前能跑的版本也回不去了。但如果你之前提交过：

```jsx
git checkout .    # 放弃所有改动，回到上次提交的状态
```

  项目又能跑了！

**🤖 Prompt：**

```jsx
我的代码改乱了，想回到上一个能跑的版本。

请告诉我：
1. 怎么放弃当前所有改动，回到上次 commit
2. 怎么查看之前的 commit 记录
3. 怎么回到更早的某个版本
```

---

# Day 2:

### v0.1 - 让 MVP 跑起来

> 🎯 今日目标
> 
> 
> 做一个最简单但**有业务价值**的版本：能创建订单，能生成 Care Plan。（提示一下，昨天我们提到一个订单里包含用户名字，药品，provider名字，包含care plan。 ）
> 
> Day 2 结束时，你应该能
> 
> 1. 设计了数据库
> 2. 设计了一个api
> 3. call llm
> 4. 交患者信息 → 拿到 Care Plan
> 
> 其它任何优化都不要考虑！
> 

---

## ⚠️ 我要学到什么程度呢？

不需要理解每一行代码是什么意思，不需要自己能手动把代码从头撸出来，不需要背下来任何语法。

为什么？

1. 面试不考手写代码。 面试官会问”为什么这样设计”，但不会让你现场默写 Django Model。能看懂、能解释就行。
2. 工作也不需要。 真实工作中大家都是 vibe coding —— 让 AI 生成代码，你负责理解和调整。没人手写每一行。
3. 这些东西第一次看会发懵，而且学习api的最好的方式就是从各个角度去练习。练习CRUD patient, provider, care plan 等等。你会发现 — **根本都是一个套路！**我们会在接下来的十几天里每天看这个code，混个脸熟，等到最后一天看到代码心里不紧张了，我们再集中练习api。

---

## 1 API

先不写代码。**一行代码都不写。**

我们先把一件事想清楚：这个系统的核心动作是什么？

回到业务：一个 CVS 的医疗工作者坐在电脑前，她要做的事就一件——**把病人的信息填进去，拿到一个 care plan。**

就这么简单。输入 → 输出。

那如果让我设计"一个 API"来完成这件事，就是：

`前端把病人信息发给后端 → 后端生成 care plan → 返回给前端`

API 是什么？就是前端和后端之间说话的方式。前端说"我要这个"，后端说"好，给你"。

如果现在不理解，就记住这句话就行，随着后面的学习你会越来越理解。可以看这个：

关于api是什么：https://www.xiaohongshu.com/explore/691f8166000000001d03b656?xsec_token=ABxSQmDjnOvbOXsmR4onRQd4ZC4ANEDuRcmwc8_R5GxaM=&xsec_source=pc_user

---

### 问题 1：如果让你围绕 care plan 的生成设计两个 API，会是什么？

想一分钟。

。

。

。

。

。

一个是"提交信息"，一个是"拿结果"。

`第一个：提交病人信息，请求生成 care plan
第二个：查询这个 care plan 生成好了没有，拿到结果`

---

### 问题 2：GET 是从数据库拿东西，POST 是往数据库发东西。你觉得这两个分别是 GET 还是 POST？

想一分钟。

。

。

。

。

。

第一个是"发"病人资料给后端 → **POST**

第二个是"拿"生成好的 care plan → **GET**

```jsx
POST /api/orders/      → 提交信息
GET  /api/orders/{id}  → 拿结果
```

---

### 问题 3：POST 发什么？GET 拿什么？

这个问题是最重要的一步。

**POST 的时候，你发送什么内容？**

回去看 Day 1 的需求，客户告诉我们需要哪些输入：

`患者名字、MRN、Provider、NPI、诊断、药物、病历...`

所以 POST 发的就是这些东西。全部打包成一坨数据发给后端。

**GET 的时候，你拿什么内容？拿的东西里面应该包含什么？**

想一分钟：你是这个医疗工作者，你提交了信息，现在你想查一下结果。你最关心什么？

。

。

。

。

。

你关心两件事：

1. **好了没有？** → 状态（pending / processing / completed / failed）
2. **如果好了，内容是什么？** → care plan 的内容

所以 GET 返回的至少要包含：

```jsx
如果care plan 还没生成完，那至少告诉我，到哪一步了，也就是这个订单的状态（status）
如果 completed，care plan 的内容
```

---

### 问题 4：如果让你一行代码也不写，你怎么验证这个设计对不对？

这个问题是我想让你思考的。

你现在有了两个 API 的设计。但是你还没写任何代码。**你怎么知道这个设计能不能用？**

想一分钟。

。

。

。

。

。

答案是：**你用嘴说就行。**

你现在假装自己是那个医疗工作者，走一遍流程：

```jsx
第一步：我填好了表单，点提交
        → POST /api/orders/ 发送病人信息
        → 后端说："收到了，订单号是 123"

第二步：我想知道 care plan 好了没
        → GET /api/orders/123
        → 后端说："还在生成中（processing）"

第三步：过了一会儿我再查
        → GET /api/orders/123
        → 后端说："好了！这是你的 care plan：[内容]"
```

这就叫 **走查（walkthrough）**。你不需要写代码，不需要任何工具，就用嘴把整个流程过一遍。如果你能顺畅地说完这个流程，没有卡住的地方，说明设计是对的。

**这也是面试的时候你应该做的事情**——面试官给你一个需求，你不需要马上写代码，你先把 API 设计出来，然后用嘴走一遍流程。面试官想看到的就是这个思考过程。

---

**这个就是系统设计考的剩下 40% 的内容了！再难也没有了！**

系统设计面试考三件事：

```jsx
20%  问清楚需求（Day 1 已经练了）
40%  数据库设计（之后会做）
40%  API 设计（你刚刚做完了）
```

你刚才做的事情：想清楚有几个 API、每个是 GET 还是 POST、发什么拿什么——就是 API 设计的全部。不需要记任何框架、任何语法。**能想清楚，能说清楚，就够了。**

。

。

。

。

。

---

## 2 实现MVP

### 调用 LLM

**用最简单的方式：同步调用**

需要买api key， Claude/ GPT都行，$5就够。

[https://platform.claude.com/login?returnTo=%2F%3F](https://platform.claude.com/login?returnTo=%2F%3F)
[https://platform.openai.com/settings/organization/api-keys](https://platform.openai.com/settings/organization/api-keys)

---

现在数据库的design部分你想明白了，api也设计好了，LLM key也有了，可以vibe coding了。

从简单的mvp开始，因为我们并不想一次性生成一个完美的project，（因为工作中也没有完美的project，都是要根据用户需求的变化而变化，根据政策改变而改变。）

所以：

```
现在先给我最小的一个能跑通这个流程的code就行，里面的限制条件先不用管，
先不用 check 边界条件，先不做 warning, error 检查，

让我把前端 + 后端 + postgresql数据库 + LLM生成一个careplan的这一个api跑起来就行，生成careplan，careplan从生成到结束可以有不同状态，比如pending → processing → completed/failed，且只有在 completed的状态时前端才显示care plan，先做成sync的，我可以在生成的时候等待。
用 docker，python, Django，不要 test cases，不要 websocket，不要 queue，不要 worker，不要任何 fancy 的技术，这些技术我后续会逐步加上，但是我想一点点学习，并且体验缺点，才更让我记忆深刻。
我想体验一下这个实现的最小mvp，尽量在一日内给我所有的code,不要分成 Controller-Service-Repository 这个分层模式
```

follow up question是：

```jsx
怎么run？
```

现在你把最小mvp跑出来之后，其实这个项目最核心的内容你已经实现出来了,真正的工作和生活里面也是这样,就是最核心的内容其实很简单就能实现,但主要是后面的优化，修改bug，等会花费更多的时间。

现在可以让ai加上更多的api和前端对应的button，但是不要加上check error, warning等内容。

```jsx
在之前的基础上只加上下载的功能，search的功能。还是不要加上check error, warning等等内容。
也不加其它的技术。
```

### 🔍 现在回头看看代码

项目跑起来了，现在**回头理解一下代码（**这个是问题最多的地方, 就是我们把code生成了之后, 我们不知道它是怎么跑的。这一步应该是花费大约60分钟的时间来做）不需要背下来，能看懂”这段代码在干什么”就行。

tips1: 你可以发截图给AI

tips2: 你可以看一下这个视频，讲了怎么加入debug的点

https://www.youtube.com/watch?v=3HiLLByBWkg

```jsx
现在我想debug一下这个代码, 我想从前到后,在这个生成order的里面加上一些debug的breakpoint,
这样我能知道接口在哪里,下一步调用的是哪个文件的哪个function我应该怎么设置,点击什么? 
是否需要用到Postman? Postman怎么用？
```

### 关于这个章节需要学到什么程度：

需要能根据ai的引导自己把get api的 code写出来。

```jsx
现在你已经把post api给我生成出来了,我想自己做一下get api,我想请你引导我一步一步把它写出来。
我现在的想法应该是既然我要get的话,
我应该是首先有一个ID或者username或者email这种unique的东西能让我搜索,你觉得呢? 
```

### 3. 关于里面的Docker 开发环境

ai已经帮你把docker写出来了。但是关于docker是什么，干什么用的， 你完全不用理解，因为这个东西的定义太脱离日常生活了，你直接用就好，如果你想知道继续理解docker，你就问ai：

```jsx
如果没有docker，这个项目应该怎么写？怎么设置？
帮我vibe coding 一个新的项目出来，这次不用docker
```

### **Day 2 结束时你应该能：**

1. POST 创建一个订单
2. 等待 10-20 秒
3. 看到返回的 Care Plan
    - GET 拿到一个订单（你做的）
    - 下载一个订单（ai做的）

---

## Day 2 完成！

✅ v0.1 能跑了！能生成 Care Plan 了！

但是现在所有的code都挤在一两个文档里面，没关系= 

---

明天我们学习数据库

# Day3 数据库

💡 为什么不直接让cvs工作人员使用sql去数据库查？

**第一：安全**

直接操作数据库很危险。你让一个医疗工作者直接写 SQL？`DELETE FROM patients; 整个表没了`API 是一道墙。用户只能做你允许的操作——提交订单、查询结果。你不提供一个删数据的API,就删不。而且 API 可以加权限控制、加日志。谁在什么时候查了什么、改了什么，全有记录。直接连数据库，这些全没有。

即便是同一个公司，不同组，Amazon CEO Jeff Bezos 在 2002 年发过一个内部命令：

`1. 所有团队必须通过 API 暴露数据和功能
2. 团队之间只能通过 API 通信
3. 不允许直接访问其他团队的数据库
4. 违反者会被开除`

**第二：数据验证**

用户填了一个病人名字叫 "John123"，名字里带数字，你接受吗？NPI 填了 5 位数，你接受吗？

**第三：并发——两个人同时写怎么办？**

数据库就一个，就像一个本子。一个人往本子上写东西，没问题。两个人同时写，也还行。但是 100 个人同时拿笔往同一个本子上写呢？要么写乱了——你写了一半，我也在写，最后写出来的东西谁的都不对。要么排队——数据库说"一个一个来"，第 100 个人就得等前面 99 个人都写完。那就慢了。**数据库能同时处理的请求是有上限的。** 超过这个上限，要么变慢，要么直接崩。

API 在中间能干什么呢？**挡一层。**100 个请求进来，API 层可以先接住——有些是重复的，直接打回去，不用到数据库。有些是查询，缓存里有答案，直接返回，也不用到数据库。最后真正需要数据库处理的，可能就剩 20 个。

**第四：扩展性（Scale）**

这是面试最常考的点之一——**怎么让读写更快？**

当系统只有 10 个用户的时候，什么架构都行。但如果有 1000 个人同时用呢？10000 个呢？

**API 可以横向扩展（scale out），数据库很难。**

什么意思？API 服务器就是一段代码跑在一台机器上。忙不过来了？再开一台，跑一样的代码，前面放一个负载均衡（load balancer）分流就行：

负载均衡就是海底捞门口拿号的那个服务员——你来了，她看哪个区有空桌，就把你领到那个区去。她不做菜（不处理api），不端盘子，就干一件事：看哪边空着，把人分过去。

```jsx
                    ┌── API 服务器 1
用户 → 负载均衡 ──→├───── API 服务器 2  ──→ 数据库
                    └── API 服务器 3
```

API 服务器可以随便加，因为它们是"无状态的"——每个请求进来，处理完就走，不记住任何东西。数据都在数据库里。

**但数据库呢？** 数据库确实有一些扩展手段——读写分离（主库写、从库读）、分区（partitioning）、分片（sharding）。但这些都比加一台 API 服务器复杂得多，而且有很多限制。比如 sharding 之后跨分片的查询就很麻烦。

所以业界的共识是：**把压力尽量挡在 API 层，而不是让压力直接打到数据库上。** API 层可以做缓存（cache），可以做限流（rate limiting），可以做排队。数据库是最宝贵的资源，要保护它。这些名词不用理解，我们后续会接触。

### 面试考什么？

很多人说计算机的面试会考一些八股，但其实考的从来都不是八股，问的也不是那个标准答案。他问的是你在实际的应用中是怎么选择的、是怎么用的。你不仅要知道它是什么，还要知道它怎么样，但最重要的是你有没有这个选择能力。你光学了各种数据结构，但你知不知道什么时候用哪个？哪个好哪个坏？优点缺点是什么？为什么在你这个场景下，你会去用这个？他问的从来都不是凭空问的，都是根据你某一个项目来问的。

---

**给 New Grad / Intern 的说明：**

面试官不会让你从零设计一个复杂的数据库架构。但他可能会问：

- "你这个项目为什么用 MySQL 而不是 MongoDB？"
- "如果数据量变大了，你会怎么考虑？"

**这个是模拟系统面试轮，虽然ng/intern 一般没有这轮，但是如果有，也就是考这个数据库的设计还有api的design了。**各占40%，剩下20%是clarify questions，我们已经在day1 练习过了

### 想一下你会怎么设计数据库？

先不想技术。回到业务：CVS 工作者填了一个表单，里面有病人名字、医生名字、药物、诊断、病历。后端生成了一个 care plan。

**问题 1：这些信息你打算怎么存？全部塞进一个表格行不行？**

想一分钟。

。

。

。

。

。

你想象一下一个 Excel 表，一行就是一个订单，所有信息都在这一行里：

（这里为了做解释,我加上了生日手机号, 这个其实不在需求文档里面, 只是为了解释数据库我加的，之后还是按照需求文档来）

```jsx
| 病人名 | 生日   | 手机   | 医生名 | 医生NPI     | 药物  | Care Plan   | 状态      |
```

10 条数据，没问题。100 条，也还行。

但是现在有个病人叫张三，他来了 5 次，开了 5 个不同的药。你的表变成这样了：

```jsx
| 病人 | 生日        | 手机         | 医生名 | 医生NPI     | 药物  | Care Plan   | 状态      |
| 张三 | 1979-06-08 | 13800001111  | 李医生 | 1234567890 | 药物A | care plan 1 | completed |
| 张三 | 1979-06-08 | 13800001111  | 李医生 | 1234567890 | 药物B | care plan 2 | completed |
| 张三 | 1979-06-08 | 13800001111  | 李医生 | 1234567890 | 药物C | care plan 3 | pending   |
| 张三 | 1979-06-08 | 13800001111  | 李医生 | 1234567890 | 药物D | care plan 4 | completed |
| 张三 | 1979-06-08 | 13800001111  | 李医生 | 1234567890 | 药物E | care plan 5 | failed    |
```

你发现问题了吗？张三、生日、手机、"李医生"、医生NPI 重复了 5 遍。

**问题 2：如果张三改了名字（比如结婚冠夫姓），你要改几个地方？**

。

。

。

5 个地方。漏改一个就出错了。如果张三来了 100 次呢？改 100 个地方。

---

**问题 3：那你觉得怎么解决这个重复的问题？**

想两分钟。

。

。

。

。

。

。

。

。

张三的名字、张三的个人信息 在 5 行里重复了 5 遍。那如果张三的信息我们**只存一遍**呢？

把张三的信息单独放一个地方：

```jsx
| 张三 | 1979-06-08 | 13800001111  

```

就这一行，存一次。

然后订单那边不再重复写"张三、 1979-06-08 、13800001111  、李医生、1234567890"，每个订单只记"这个订单的病人是谁"——去那个地方找就行。

李医生也一样，信息只存一份。订单只记"这个订单的医生是谁"。

想一下这个医生的信息应该存哪些。

**问题 4：但是"这个订单的病人是张三"——如果有两个张三呢？你靠名字能分清楚吗？**

想一分钟。

。

。

。

。

。

分不清。所以给每个病人一个**编号**，不会重复的、唯一的。订单里不存名字，存编号。

```jsx
病人表：
| 编号    | 名字 | 生日       | 手机号 
|  001   | 张三 | 1979-06-08 | 13800001111  

订单表：
| 编号   | 病人编号 | 药物  |
|  001   |    1    | 药物A |    ← 病人编号1，去病人表找编号1，就是张三
|  002   |    1    | 药物B |
|  003   |    1    | 药物C |
```

现在张三改名字，只改病人表里那一行。订单表不用动，因为它存的是编号，不是名字。

这个"在订单表里放一个编号，指向另一个表"的做法，有个名字，叫**外键**。你已经想到了这个思路，现在只是知道它叫什么了而已。

所以最终我们的数据库长这样：

```jsx
┌─────────────────────┐          ┌─────────────────────────┐
│     病人 Patient     │          │     医生 Provider        │
├─────────────────────┤          ├─────────────────────────┤
│ 编号                 │          │ 编号                     │
│ 名字                 │          │ 名字                     │
│ MRN                  │          │ NPI                      │
│ DOB                  │          │                          │
└────────┬────────────┘          └────────┬────────────────┘
         │                                │
         │ 一个病人可以有多个订单           │ 一个医生可以有多个订单
         │                                │
         ▼                                ▼
┌──────────────────────────────────────────────────────┐
│                      订单 Order                       │
├──────────────────────────────────────────────────────┤
│ 编号                                                  │
│ 病人编号  ← 指向病人表                                 │
│ 医生编号  ← 指向医生表                                 │
│ 药物                                                  │
│ 诊断                                                  │
│ 病历                                                  │
└────────────────────────┬─────────────────────────────┘
                         │
                         │ 一个订单对应一个 care plan
                         │
                         ▼
┌──────────────────────────────────────────────────────┐
│                  Care Plan                            │
├──────────────────────────────────────────────────────┤
│ 编号                                                  │
│ 订单编号  ← 指向订单表                                 │
│ 内容                                                  │
│ 状态（pending → processing → completed / failed）      │
└──────────────────────────────────────────────────────┘
```

问ai：

```jsx
现在生成一些mock data，和code，让我import到数据库，数据库我会用TablePlus打开。
```

### 关于数据库：

如果ai直接生成了sqlite，问ai

```jsx
为什么给我sqlite？跟postgresql 有什么区别？
我之后要deploy到aws，建议用哪个？
给我PostgreSQL吧,因为我在学习,我不想给我造成更多的confusion。
```

需要用到的桌面软件：DBeaver, TablePlus 两个都行，都是免费的。这两个的目的就是能在数据库里面看到数据,如果不下载的话,用一些command也一样能看到数据。 

![Screenshot 2026-01-25 at 12.55.37 PM.png](careplan%E8%AF%BE%E7%A8%8B%20-%202sum/Screenshot_2026-01-25_at_12.55.37_PM.png)

### 面试：

不需要完全做到能复制这个数据库的设计，但是要大概能理解这个思路，因为我们后续会进行一些数据库的操作，会让我们更深一步的理解为什么要这样设计。

## Day 3 完成！

结合昨天的内容，我们能生成careplan 并存入数据库了。

---

❓ 但是… 你发现问题了吗？

**提交表单后，页面卡住了 10-20 秒！** 用户体验太差了。

👉 明天我们来解决这个问题。

# Day 4:  太慢了！引入消息队列

> 昨日痛点：**提交表单后，页面卡住了 10-20 秒，**用户体验太差了。

🎯 今日目标
> 
> 
> 理解为什么需要异步处理，引入消息队列的概念，并实际体验"把任务放进队列"。
> 
> **你做的时候会发现care plan不再生成了，且数据库里 status 不是finished，这是我们期待的。**
> 

---

## 1 核心问题：LLM 调用很慢怎么办？

我们再澄清一个点，程序是给人用的，人是没有耐心的。如果现在的小红书每点开一个帖子需要等 10 秒、5 秒、甚至是 1 秒，人都会关闭小红书打开其它的社交网站的。没有用户，公司就倒闭。所以程序员的出现就是尽量缩短点开每个帖子的时间，不让用户退出。**所以程序员就是做用户体验优化的。**

有了这个认识，现在想一个问题：

假如你在cvs上班，负责给病人开药，你在 call LLM 的时候要等待，你觉得这个等待的时间间隔怎么样，你愿意等待吗？如果你愿意，那在等待的时候顾客又在催促呢？如果你在等待的时候已经是下午 4 点要下班了，接待了一天的病人耐心耗尽了呢？还有你如果在等的时候，知道你朋友在 Walgreens 上班人家用的软件根本不用等呢？你什么心情？想不想跟你老板提意见，赶紧把这个软件给我换掉？

用程序员的话说（也就是面试时显示你更专业的词）是，你现在经历的是**同步调用**的问题：

```jsx
用户提交 → 后端收到 → 调用 LLM (等待 20 秒) → 返回结果
                               ↑
                           问题在这里！
                        用户干等着，什么都做不了
```

---

### 你的解决办法可能包含：

**有没有这样一个东西，让后端在生成 Care Plan 的时候，我还能继续place下一个order？**能不能在我在cvs给病人生成了一个careplan的时候，让我能接着把柜台后面排队的10个人都提交了？这个系统先只告诉我收到了就行，然后在后台慢慢生成？等后台处理好了再返回给我，如果后台没有处理好，后台自己再多占用几分钟reprocess一下，什么时候好了什么时候给我。

比如你在 CVS 工作，一个病人需要取 4-5 种药，你可以把每种药的 Care Plan 都点击生成。第一个药在生成中，你就可以继续输入第二个药，不会被第一个阻塞。

以此类推你就可以提交 4-5 种，然后让顾客去旁边等待 10 分钟逛逛零食区，你继续接待下一个病人。等上一个病人的 4-5 种药都生成完毕，再叫他来取。

这样第一个病人不用在柜台前傻等 10 分钟，第二个病人不用等第一个病人全部结束，你可以继续接待更多的病人，一举三得。

这个“系统先只告诉我收到了就行，然后在后台慢慢生成” 就是异步！就是这么自然而然！是不是根本不用死记硬背？是不是这个办法你就能想出来？只是想不出一个“异步”这样fancy的词？这就是我们主动思考的意义，计算机根本不难，但是你一旦从“异步”这种非日常，非生活化的词开始学，就变的很难。

## 2 面试考点

问题的本质不是"LLM 调用慢"，而是"**用户需要等待太久**"。

> 💡 LLM 调用部分也可以优化，比如多买几个 API key 处理高峰期的吞吐量。但这不是intern/ ng面试考查点。考查点在于：作为程序员，你怎么解决"用户需要等待太久"的问题。
> 

解决思路：让用户不需要等待 → **异步处理**

---

最直接的想法，应该是都先放进数据库，然后API返回类似”知道了，接收了，我在生成了，结束了我会我会告诉你”。然后有一个扫描机制，在数据库里找到所有status 为pending 状态的，还没开始生成的那些，慢慢生成。

**Prompt 1：先问最直接的想法**

```jsx
我有一个系统：用户提交订单后，后端把数据存到数据库，status 设为 pending。

然后我需要后台去处理这些 pending 的订单。

我的想法是：写一个程序，每隔 2 秒去数据库查一下有没有 pending 的订单，有的话就处理。

这个方案可行吗？有什么问题？
```

---

**Prompt 2：追问数据量大的情况**

```jsx
如果数据库里有 100 万条订单记录，其中只有 3 条是 pending。

我每 2 秒执行一次：SELECT * FROM orders WHERE status='pending'

这样做有什么问题？

如果status 设置为index呢？会不会好点？
```

---

**Prompt 3：追问实时性**

```jsx
用户提交订单后，我的程序要等到下一次扫描才能发现这条新订单。

如果扫描间隔是 2 秒，最坏情况用户要等多久？

如果我想让用户提交后立刻被处理，扫描数据库这个方案能做到吗？
```

---

知道了缺点之后，下一个自然而然的想法应该是，**能不能有一个单独的空间，让我能把所有的pending的放在那里？**处理好了之后再把内容更新到数据库，以及返回给我？

问ai：

```jsx
能不能有一个单独的空间，让我能把所有的pending的放在那里？
****处理好了之后再把内容更新到数据库，以及返回给我？
这样的优缺点是什么，可不可行。如果有这样的东西，叫什么？
```

ai可能提到一个词：消息队列

## 3 消息队列是什么？

**答案就在名字里：**

- **消息** =  careplan_id
    
    既然是放消息的，放什么消息比较好？全部的信息，包含用户名字，药物名字，provider名字还是什么？自己想一想。（这个比较难，不需要做出决定，只要有这个意识知道要分析就行）
    
- **队列** = 一个存储空间（符合queue的特性,first in, first out）

就这样。**消息队列就是一个队列，队列顾名思义就是存放东西的地方，本身没有任何功能。**

```jsx
┌─────────────────────────┐
│      消息队列 (Redis)    │
│                         │
│   careplan_id: 1        │
│   careplan_id: 2        │
│   careplan_id: 3        │
│                         │
│   （就是个盒子，         │
│     放东西进去，         │
│     等人来取）           │
└─────────────────────────┘
```

**它不会：**

- ❌ 自动处理任务
- ❌ 通知任何人
- ❌ 做任何事情

**它只会：**

- ✅ 存数据
- ✅ 等别人来取

---

### 消息队列的特点

| 特点 | 说明 | CVS场景 |
| --- | --- | --- |
| **解耦** | 放任务的人和取任务的人互不认识 | 你不用等后台处理完，后台不用管你在接待谁 |
| **异步** | 放完任务就走，不用等处理完 | 点击生成就继续下一个，不傻等 |
| **缓冲** | 任务来得太快？先存着 | 突然来10个病人，任务都存着，慢慢处理 |

---

## 4 架构

```jsx
┌─────────────┐      ①提交      ┌─────────────┐
│   Frontend  │ ──────────────▶ │   Backend   │
│   (React)   │                 │   (Django)  │
└─────────────┘                 └──────┬──────┘
      ▲                                │
      │                                ├───────②存数据────────▶ ┌─────────────┐
      │                                │      (status=pending)  │  Database   │
      │                                │                        │ (PostgreSQL)│
      │                                │                        └─────────────┘
      │                                │
      │                                ├───────③放任务────────▶ ┌─────────────┐
      │                                │      (careplan_id)     │    Redis    │
      │                                │                        │   (队列)    │
      │                                │                        └─────────────┘
      │                                │
      │         ④返回"收到了！"         │
      └────────────────────────────────┘
```

| 步骤 | 操作 | 耗时 |
| --- | --- | --- |
| ① | 用户提交表单 | - |
| ② | 保存 CarePlan（status='pending'） | ~50ms |
| ③ | 把 careplan_id 放进队列 | ~50ms |
| ④ | 立即返回 CarePlan ID | **总计 ~100ms** ✅ |

### 关键区别

|  | 之前同步的时候 | 现在异步之后 |
| --- | --- | --- |
| **API 做什么** | 验证 + 调用LLM + 返回结果 | 验证 + 放进队列 + 返回"收到了" |
| **用户等待** | 10-30秒 | 200ms |
| **能否连续提交** | ❌ 必须等上一个完成 | ✅ 随便提交 |

你可能会问的ai prompt：

```jsx
从那数据库应该数据库要不要像API一样返回一个200的status呢?还是说数据库没有反应呢?
不给一个返回的回值呢?  
放到redis里面应该给一个200的status code吧?
```

（下面这个对于junior不是考查点，但是可以适当了解一下）

```jsx
为什么先存在数据库？为什么不放在队列之后就返回？
市面上什么公司在做针对什么的处理的时候先放进数据库？什么放进队列就不管了，等队列再传到数据库？
分别的优缺点是什么？
```

这样对比是不是更清楚为什么要用异步了？

## 5 实现

### 🤖 Prompt

```jsx
对于昨天这个项目，用户提交表单后会同步调用 LLM，很慢。

我想改成异步：
1. 加一个 Redis 容器到 docker-compose
2. API 收到请求后：
   - 先把 CarePlan 存到数据库（status='pending'）
   - 再把 careplan_id 放进 Redis 队列
3. 立刻返回给用户 "已收到" 和 careplan_id
4. 先不写处理队列的代码，只做"存数据库 + 放进队列"这两步，也不要主动告知前端完成了，那是我之后学习的内容。

帮我改一下代码。

```

---

### 验证成功

启动服务后，提交几个请求

```jsx
我想测试一下 看是否能让我持续提交，怎么测试？
```

**体验到了吗？至少用户部分不阻塞了！可以连续提交！至于提交之后，我们先不管。**

---

### 看看发生了什么

**检查数据库里careplan 的状态，是不是都是pending中。** 

```jsx
给我看看数据库里careplan 的状态，
```

**检查一下有没有，且是不是都在pending中。** 

```jsx
给我看看redis 里的数据，我想看看放进去没有
```

## 6 等等... 发现问题了吗？

1. 任务确实进了队列，API 也不阻塞了。 但是数据库里 status 全是 `pending` ，且Care Plan 的 content 是空的 
2. 任务就躺在 Redis 里... 没人处理

**这就对了！**

Redis 只是一个"盒子"，它只负责存数据。它不会：

- ❌ 自动处理任务
- ❌ 调用 LLM
- ❌ 通知任何人"嘿，有新任务"

它就静静地躺在那里，等别人来取。

---

## Day 4 完成！

✅ 理解了为什么需要异步处理

✅ 理解了消息队列的概念

✅ 实现了"把任务放进队列"

✅ API 不再阻塞，可以连续提交

❓ **但是...任务躺在队列里没人处理啊？**

👉 明天我们来解决这个问题：写一个 Worker 去取任务。

---

## 附：消息队列选型（面试可能会问）

> 🎯 面试考点：
数据量很大的时候怎么handle？
提示：用async，加queue。
> 

# Day 5:  Celery, Micro-services

> 🎯 今日目标
**今日重在理解，这个Celery 不是面试的考点，即便系统设计里也不是考点。考点为0。**
> 
> 
> 感受一下：如果没有框架，异步处理要写多少代码？然后引入 Celery，看看代码量差多少。
> 
> **不需要你真的手写，让 AI 生成，你感受一下复杂度就行。**
> 
> 今天我们想引入的一个程序员重要的思维：**不要重复造轮子。**就是如果一个问题发生的够普遍，大概率别人已经有解决办法了，这个解决办法就是轮子。不要重复造轮子的意思就是不要再解一个已经被解决的问题，直接用别人的解决办法就行了。
> 
> 你会发现虽然生成care plan了，但是前端不刷新就不更新。这也是我们期待的结果。
> 

---

## 1 消息放进队列后，然后呢？

昨天我们把任务放进了 Redis 队列。

**问题来了：然后呢？**

Redis 是个什么东西？它就是一个**存数据的地方**，仅此而已。

```jsx
┌─────────────────────────────┐
│           Redis             │
│                             │
│   任务1: order_id=101       │
│   任务2: order_id=102       │
│   任务3: order_id=103       │
│                             │
│   （就静静地躺在这里...）      │
│   （不会做任何事...）         │
│   （不会通知任何人...）        │
│                             │
└─────────────────────────────┘
```

**Redis 不会：**

- ❌ 自动处理任务
- ❌ 触发一个 API call
- ❌ 通知你"嘿，有新任务来了"
- ❌ 做任何主动的事情

**Redis 只会：**

- ✅ 存数据
- ✅ 等别人来取数据

它就是个"盒子"。你往里面放东西，它存着。但它不会帮你做任何事。

---

**那任务谁来处理？**

你需要自己写一个程序，定期检查一下："有任务吗？有任务吗？有任务吗？"

用程序员的话说，你写的这个程序就叫 **Worker**。

```jsx
┌──────────┐                    ┌─────────────┐
│  Worker  │ ── "有任务吗？" ──▶ │    Redis    │
│          │ ◀── "没有" ──────── │             │
│          │                    │             │
│          │ ── "有任务吗？" ──▶ │             │
│          │ ◀── "没有" ──────── │             │
│          │                    │             │
│          │ ── "有任务吗？" ──▶ │    id        │
│          │ ◀── "有！给你" ──── │             │
│          │                    │             │
│  （处理任务）                   │             │
└──────────┘                    └─────────────┘
```

这种模式叫 **Pull（拉取）**—— Worker 主动去"拉"任务。

---

**剧透：AWS 上不是这样的**

AWS毕竟是付费的服务，人家多加了功能，不需要我们总去查看。

AWS 的 SQS + Lambda 是 **Push（推送）** 模式：

`任务进来 → SQS 主动触发 Lambda → Lambda 处理完就结束`

不需要一个一直运行的 Worker！但那是 Day 11 的内容，本地开发我们先用 Pull 模式。

---

## 2 手写 function

你现在是不是想直接问 AI：

```jsx
帮我写一个 function 来处理 Redis 队列里的任务。
```

⚠️ **停！在问 AI 之前请先思考**

先自己想一下：这个 function 最基本要做什么？会遇到什么问题？

**最基本的：要去 Redis 拉任务（Pull）**

但马上你会有问题：

| 你的问题 | 进一步思考 |
| --- | --- |
| 多久拉一次？ | 每秒？每 5 秒？每分钟？ |
| 没任务的时候呢？ | 长周末三天没订单，还要每 5 秒拉一次？空转三天？ |
| 任务太多的时候呢？ | 突然来 100 个订单，每 5 秒处理一个要 500 秒？ |
| 拉到任务后呢？ | 调用 LLM，存数据库 |
| LLM 调用失败呢？ | 重试？放弃？怎么重试？ |
| Worker 自己崩了呢？ | 正在处理的任务怎么办？ |

我们必须意识到一点：**所有计算机方向的内容都是人发明出来的**。

既然是人发明的，那任何东西的发明都是在**有需求的基础上**发明出来的，否则这个东西在最开始就不会被发明出来。所以与其去理解某个东西能干什么用，我们必须**从”为什么这个东西会被发明出来”开始理解**。

对于已经上完大一大二的学生来说，你已经有了一些计算机的基础知识。我们对于这里面的任何内容都应该是**出于理解的目的**，在任何情况、任何时候都**不能死记硬背**。

- 一旦死记硬背，面试就**一定不会过**
- 一旦出于理解的目的，面试就**一定会过**

**怎么才能理解？** 去问 AI：
- “为什么这个东西会被发明出来？”
- “它解决了之前哪些不能解决的问题？”
- “在它出现之前，人们是怎么做的？”

**你发现了：光是"去拉任务"这一件事，就有一堆问题要考虑。**

想不出来？没关系，先问 AI 要一个最基础的版本，跑起来，踩坑了再说。这个步骤不可省略！因为之后你根本就不需要理解worker是什么，根本不需要死记硬背了。

```jsx
我需要手写一个 function 来处理 Redis 队列里的任务。先不用celery。我在学习这个过程。

完成后不要主动告诉前端，那是我明天要学习的内容。不要用polling, 不要sse，不要自动更新前端，
我就是想体验前端没有自动更新这个痛点，我就是想体验如果我不主动刷新，我就不能看到careplan已经完成了。

先帮我实现一个最基本的版本：
1. 从 Redis 拉任务
2. 调用 LLM 生成 Care Plan
3. 把care plan存到数据库
```

## 3 用 Celery 有多简单？

**🤖 Prompt：**

```jsx
帮我用 Celery 写一个异步任务，功能：
1. 调用 LLM 生成 Care Plan
2. 支持失败重试（最多 3 次，指数退避）
3. 更新数据库中的订单状态
4. 不要用polling, 不要sse，不要自动更新前端，我就是想体验前端没有自动更新这个痛点，
我就是想体验如果我不主动刷新，我就不能看到careplan已经完成了。
5. 帮我把celery的code写成，然后告诉我怎么测试celery在工作，或者在哪里来验证worker在工作就好
```

> 🎯 面试考点
> 
> 
> Q: "如果 LLM 调用失败怎么办？" — **常考**
> 
> A: "配置自动重试（比如最多 3 次），使用 exponential backoff。如果都失败，标记 status='failed'，用户可以手动点击重新生成。"
> 

---

## 4 结构

```jsx
┌─────────────┐  ①请求   ┌─────────────┐
│    前端     │ ───────→ │ Web Server  │
│  (React)    │          │  (Django)   │
└─────────────┘          └──────┬──────┘
      ▲                         │
      │                         ├────②存数据────→ ┌─────────────┐
      │                         │  (status=       │  Database   │
      │                         │   pending)      │ (PostgreSQL)│
      │                         │  ←──返回成功──   └─────────────┘
      │                         │
      │                         ├────③放任务────→ ┌─────────────┐
      │                         │  (careplan_id)  │    Redis    │
      │                         │  ←──返回成功──   │   (队列)    │
      │     ④返回"收到了"        │                 └──────┬──────┘
      └─────────────────────────┘                       │
                                                        │ ⑤取任务
                                                        ▼
                                                 ┌─────────────┐
                                                 │   Worker    │
                                                 │  (Celery)   │
                                                 └──────┬──────┘
                                                        │
                                                        │ ⑥调用 LLM
                                                        │
                                                        ├────⑦更新数据────→ Database
                                                        │  (status=completed)
                                                        │  ←────返回成功────
                                                        │
                                                        ⑧ 然后呢？
                                                        前端不知道！
```

| 步骤 | 谁 → 谁 | 做什么 | 返回什么 |
| --- | --- | --- | --- |
| ① | 前端 → Web Server | 提交表单 | - |
| ② | Web Server → Database | 存数据（status=pending） | 成功/失败 |
| ③ | Web Server → Redis | 放任务（careplan_id） | 成功/失败 |
| ④ | Web Server → 前端 | 返回响应 | {"id": 123, "status": "pending"} |
| ⑤ | Worker → Redis | 取任务 | careplan_id |
| ⑥ | Worker → LLM | 调用 LLM | 生成的 CarePlan 内容 |
| ⑦ | Worker → Database | 更新数据（status=completed） | 成功/失败 |
| ⑧ | ？？？ | 前端不知道完成了 | - |

## 5 Microservices

你可能没意识到，但你刚刚把系统从"一个程序"拆成了"多个服务"：

```jsx
之前（Day 2）：
┌─────────────────────────────┐
│         一个程序             │
│  Django 接收请求 + 调用 LLM   │
└─────────────────────────────┘

现在（Day 4）：
┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐
│  Django  │  │  Worker  │  │  Redis   │  │ Database │
│Web Server│  │ (Celery) │  │  (队列)   │  │PostgreSQL│
└──────────┘  └──────────┘  └──────────┘  └──────────┘
   各自独立运行，通过网络通信
```

这就是 **微服务（Microservice）** 的基本概念。

---

**为什么要拆？**

| 好处 | 例子 |
| --- | --- |
| 独立扩展 | Worker 忙？多开几个。Web Server 不用动 |
| 独立部署 | 改 Worker 代码，不用重启 Web Server |
| 故障隔离 | Worker 挂了，用户还能提交，只是处理慢 |

**坏处呢？**

| 坏处 | 例子 |
| --- | --- |
| 通信变复杂 | Worker 完成了，Web Server 不会自动知道 |
| 调试变难 | 问题可能在任何一个服务里 |
| 网络问题 | 服务之间通过网络通信，可能断开 |

---

**面试怎么说：**

```jsx
Q: 你这个项目为什么要拆成 Web Server 和 Worker？

A: 因为 LLM 调用很慢。如果在 API 里同步调用，用户要等 30 秒。
   拆成 Worker 之后，API 立刻返回，Worker 在后台处理。
   而且可以独立扩展，Worker 忙的时候多开几个。
```

## Mock 的概念

Worker 跑起来了，但你每次测试都要真的调用 LLM 吗？

**不行，因为：** 太慢（每次 10 秒），花钱

**解决方案：Mock** — 假装调用了 LLM

你可以让 AI 帮你写一个假的 LLM 函数，它不真的调 API，而是直接返回一段固定的 care plan 文本。这样你测试的时候，Worker 的整个流程都能跑通，但不花钱、不等待。

---

## Day 5 完成！

✅ 感受了手写 function 的复杂度

✅ 理解了为什么用 Celery worker

✅ 实现了异步任务

❓ 但是... 如果我不主动刷新，我就不能看到careplan已经完成了。

👉 明天实现。

# Day 6: 前端怎么知道完成了？

## 1 问题

看上一天的流程图，到第 ⑧ 步：

```jsx
Worker 更新了数据库（status=completed）
但是前端不知道！
前端还在显示"正在生成..."
```

---

## 2 你的第一反应

直觉上我们会想：写个东西定期扫数据库，发现 status 变成 completed 了，就通知前端。

对吧？这个想法非常自然。问问 AI：

```jsx
Worker 处理完任务后，把数据库里的 status 更新成 completed 了。
但是前端不知道。

我的想法是：写一个后端定时任务，每隔几秒扫一次数据库，
找到 status 变成 completed 的记录，然后通知前端。

这个方案可行吗？有什么问题？
```

AI 会告诉你一个关键问题：**"通知前端"这一步，你打算怎么做？**

后端没有办法主动联系前端。HTTP 的规则是：前端发请求，后端回响应。**后端不能主动给前端发消息。**

`前端 → 后端：可以（发请求）
后端 → 前端：不行（没有通道）`

你的后端扫到了 completed，然后呢？它不知道前端在哪，不知道前端的地址，没有办法"推"给前端。

## 3 那反过来呢？

后端不能主动找前端。**但前端可以主动找后端。**

那最简单的办法就是：前端自己每隔几秒问一次后端——"好了没？好了没？好了没？"

这个就叫 **Polling（轮询）**。就是这么简单，就是这么直觉。

```jsx
我用 Polling 实现前端查询任务状态。

问题：
1. 轮询间隔设多少秒合适？1秒？3秒？10秒？
2. 间隔太短有什么问题？
3. 间隔太长有什么问题？
4. 有没有更智能的方式？比如一开始快，后面慢？

我的场景：
- CarePlan 生成大概需要 10-30 秒
- 用户量不大，几十个药剂师
```

---

注意：Polling 和你最开始想的"扫数据库"本质上是同一个动作——查数据库看 status。区别只是**谁发起的**：你想的是后端自己扫，Polling 是前端发起、通过 API 让后端去查。因为后端没法主动通知前端，所以只能让前端来主动问。

Polling 是最简单的方案，但还有更高效的方式：SSE（Server-Sent Events）。SSE 可以让后端主动推送给前端，不用前端一直问。但这涉及到 Redis Pub/Sub、进程间通信等概念，Intern / New Grad 面试基本不考。如果你感兴趣，可以看这个，这个是bonus，先继续往后做，如果感兴趣，再做这个。

[Bonus: 深入理解实时通知（SSE + Redis Pub/Sub）](https://www.notion.so/Bonus-SSE-Redis-Pub-Sub-2f873b2e006380ea9a1cfd3a23e6f9f0?pvs=21)

## 4 流程

```jsx
┌──────────┐      ┌──────────┐      ┌──────────┐      ┌──────────┐
│   前端   │      │Web Server│      │ Database │      │  Worker  │
└────┬─────┘      └────┬─────┘      └────┬─────┘      └────┬─────┘
     │                 │                 │                 │
     │  ①提交表单      │                 │                 │
     │────────────────▶│                 │                 │
     │                 │  ②存数据        │                 │
     │                 │────────────────▶│                 │
     │                 │  (pending)      │                 │
     │                 │                 │                 │
     │  ③返回"收到了"  │                 │                 │
     │◀────────────────│                 │                 │
     │                 │                 │                 │
     │                 │                 │    ④取任务处理   │
     │                 │                 │◀────────────────│
     │                 │                 │                 │
     │                 │                 │    ⑤更新数据     │
     │                 │                 │◀────────────────│
     │                 │                 │  (completed)    │
     │                 │                 │                 │
     │  ⑥查状态        │                 │                 │
     │────────────────▶│  ⑦查数据库      │                 │
     │                 │────────────────▶│                 │
     │                 │◀────────────────│                 │
     │  ⑧返回 pending  │                 │                 │
     │◀────────────────│                 │                 │
     │                 │                 │                 │
     │  （3秒后再问）   │                 │                 │
     │                 │                 │                 │
     │  ⑨查状态        │                 │                 │
     │────────────────▶│  ⑩查数据库      │                 │
     │                 │────────────────▶│                 │
     │                 │◀────────────────│                 │
     │  ⑪返回completed │                 │                 │
     │◀────────────────│                 │                 │
     │                 │                 │                 │
     │  ⑫显示结果      │                 │                 │
     │                 │                 │                 │
```

---

## 5 实现

**我们需要在后端添加一个查询状态的 API**

🤖 Prompt：

```jsx
我的 CarePlan 项目用 Django + React + Docker。

Worker 处理完成后，前端不知道。请帮我实现 Polling：

后端：
1. 添加一个 API：GET /api/careplan/<id>/status/
2. 返回 careplan 的 status 和 content（如果 completed）

前端：
1. 提交表单后，拿到 careplan_id
2. 每隔 3 秒调用状态 API
3. 如果 status 是 completed，停止轮询，显示结果
4. 如果 status 是 failed，停止轮询，显示错误

请给我完整代码。
```

---

## 6 面试考点

**Q: 前端怎么知道任务完成了？**

```jsx
A: 用 Polling。前端每隔几秒请求一次后端查状态。
   状态变成 completed 就停止轮询，显示结果。
```

**Q: Polling 有什么缺点？**

```jsx
A: 浪费请求。
```

**Q: 有更好的方案吗？**

```jsx
A: 可以用 SSE，后端主动推送给前端。
   但 Polling 实现简单，用户量小的时候够用了。
```

---

## Mock 的概念

Worker 跑起来了，但你每次测试都要真的调用 LLM 吗？

**不行，因为：** 太慢（每次 10 秒），花钱

**解决方案：Mock** — 假装调用了 LLM

你可以让 AI 帮你写一个假的 LLM 函数，它不真的调 API，而是直接返回一段固定的 care plan 文本。这样你测试的时候，Worker 的整个流程都能跑通，但不花钱、不等待。

```jsx
我的 Worker 会调用 LLM 生成 care plan。
我想在开发和测试的时候不真的调用 LLM，而是用一个 mock 的假函数代替。

请帮我实现：
1. 一个 mock 的 LLM 函数，直接返回一段固定的 care plan 文本
2. 通过环境变量或配置来切换：开发时用 mock，生产时用真的 LLM
3. 让我能用 mock 跑通整个 Worker 流程：从 Redis 取任务 → 调用 mock LLM → 存到数据库
```

## Day 6 完成！

✅ 理解了 Polling 的原理

✅ 前端能自动知道完成了

---

❓ 但是… 输入没有验证！用户可以输入任何东西。

👉 明天加上输入验证。

# Day 7 拆分

现在打开 views.py 看看。

**这个文件已经经历了五轮修改——同步调用、改异步、放队列、Celery 任务、Polling 状态查询……** 所有逻辑都塞在一起，你还找得到哪段代码在干什么吗？

下一步我们还要加输入验证和重复检测。你想继续往这个文件里塞几百行校验逻辑吗？

👉 下一步：先把代码整理一下。

# 代码太乱了！拆分架构

> 🎯 今日目标
> 
> 
> 把所有逻辑都堆在 views.py 里的代码拆成清晰的分层结构。
> 
> **今天不加任何新功能，只是把代码搬到正确的位置。功能和之前一模一样。**
> 

---

## 先做一件事：数一下你的 views.py 有多少行

不需要一行行数——打开文件，看右下角的行数就行。或者问 AI：

`我的 views.py 有多少行？帮我列一下里面有哪些函数，每个函数分别做了什么事。`

看完 AI 的回答之后，**想一个问题：**

你现在要找"LLM 在哪里被调用的"，你能在 10 秒内找到吗？

。

。

。

。

。

大概率不行。因为这个文件里面处理 POST 的、处理 GET 的、放队列的、查状态的、调 LLM 的、存数据库的、格式化返回数据的——全部挤在一起。

---

## 问题来了：接下来还要加什么？

回想一下需求文档，我们还没做的有：输入验证（NPI 是不是 10 位数？MRN 格式对不对？）、重复检测（同一个病人同一天提交同样的药要拦住）、导出 CSV、错误处理……

**问题 1：这些代码你打算写在哪？**

想一分钟。

。

。

。

。

。

如果你的回答是"继续写在 views.py 里"——那这个文件很快就要 800 行、1000 行了。一个月后你自己回来看这个文件，你都不知道哪段代码在干什么。

如果你的回答是"应该分开放"——那问题来了：**怎么分？按什么标准分？**

---

## 问题 2：如果让你分，你会怎么分？

不要去搜索。先用你自己的直觉想一下。

你的 views.py 里面的代码，大致在做几类不同的事情？

想两分钟。

。

。

。

。

。

。

。

。

你仔细看的话，会发现这些代码虽然都在一个文件里，但其实在做三件完全不同的事：

```jsx
第一类：接收请求、返回响应
  - 读 request.data
  - 判断用哪个 HTTP 方法
  - 返回 JSON 给前端
  - 决定返回什么 HTTP 状态码

第二类：数据格式处理
  - 把前端发来的数据整理成后端能用的格式
  - 把数据库里的数据整理成前端需要的格式

第三类：业务逻辑
  - 调用 LLM
  - 把任务放进 Redis 队列
  - 存数据库、读数据库
  - 拼 prompt
```

你去 CVS 药房取药，是不是也是这个分工？

```jsx
前台（接待）：你好，你要什么？把你的信息录入系统。
  → 对应第一类：接收请求、返回响应

前台检查：你的处方格式对吗？保险信息对吗？
  → 对应第二类：数据格式处理

后厨（配药）：根据处方配药、生成 care plan。
  → 对应第三类：业务逻辑
```

前台不需要知道药怎么配的。后厨不需要知道顾客长什么样。**每个人只管自己的事。**

---

## 问题 3：那在 Django 里，这三类代码分别应该放在哪个文件里？

你不需要知道答案。问 AI：

```jsx
我发现我 views.py 里的代码大致在做三类事情：
1. 接收HTTP请求、返回HTTP响应
2. 数据格式转换（前端格式 ↔ 后端格式）
3. 业务逻辑（调LLM、放队列、操作数据库）

在 Django 项目里，这三类代码一般分别放在什么文件里？
每个文件的命名约定是什么？为什么这样分？
```

。

。

。

。

。

AI 会告诉你 Django 社区的惯例：

| 文件 | 负责什么 | 对应 CVS |
| --- | --- | --- |
| `views.py` | 接收请求，返回响应 | 前台接待 |
| `serializers.py` | 数据校验 + 格式转换 | 前台检查处方 |
| `services.py` | 业务逻辑（LLM、队列、数据库） | 后厨配药 |
| `models.py` | 数据库表定义（已有，不用动） | 仓库 |

你可能会问：serializers.py 是什么？这个是 Django REST Framework (DRF) 里面的概念。你不需要现在完全理解它，只需要知道：**它专门负责"前端发来的数据长什么样"和"返回给前端的数据长什么样"这件事。** 之后加验证的时候你会深入用到它。

---

## ⚠️ 为什么现在才拆？

你可能在网上看过教程，第一节课就教你 MVC、分层架构、Controller-Service-Repository。

**但你想一下：如果你从来没体验过"所有代码堆在一个文件里"的痛苦，你怎么理解"为什么要拆"？**

你现在经历过了。你知道那个 views.py 有多乱。所以你现在理解的"分层架构"，和背出来的"分层架构"，是两回事。

---

## 动手拆

现在你知道了要拆成什么样，让 AI 来帮你搬代码。

**⚠️ 重要：拆之前先 git commit！** 这样如果拆坏了，你可以 `git checkout .` 回到能跑的版本。

```jsx
git add .
git commit -m "before restructure - everything in views.py"
git push
```

🤖 Prompt：

```jsx
我现在的 Django 后端所有逻辑都写在 views.py 一个文件里。
请帮我拆分到正确的位置。

要求：
1. views.py：只负责接收请求和返回响应，不做任何业务逻辑
2. serializers.py：负责数据校验和格式转换（前端 ↔ 后端）
3. services.py：负责所有业务逻辑（调LLM、放Redis队列、操作数据库）
4. models.py 不要动

约束：
- 不要改任何功能，只是把代码搬到正确的位置
- 拆完之后帮我验证所有 API 功能和之前一模一样
- 帮我列一个表格，说明每段代码从 views.py 的哪个位置搬到了哪个文件
- 不要加新功能，不要加验证，不要加错误处理，那是下一步的事
```

---

## 🔍 拆完之后，理解一下代码

跟 MVP 那一章一样，代码生成完了，**花时间理解一下它是怎么跑的。** 这个步骤不能跳过。

```jsx
帮我从前到后走一遍：当前端 POST /api/orders/ 的时候，
请求是怎么从 urls.py → views.py → serializers.py → services.py 一步步走的？
每一步做了什么？数据从什么格式变成了什么格式？

我想加一些 debug 的 breakpoint，帮我设置一下，让我能看到请求在每个文件之间怎么传递。
```

你应该能在 debug 的时候看到这个流程：

```jsx
前端 POST /api/orders/
  → urls.py：找到对应的 view 函数
    → views.py：读 request.data，交给 serializer
      → serializers.py：把前端数据整理成后端格式
        → views.py：拿到整理好的数据，调用 service
          → services.py：存数据库，放队列
            → views.py：返回 JSON 给前端
```

---

## 验证：确认没拆坏

```jsx
帮我测试一下所有功能：
1. POST 创建一个订单 → 是否正常返回？
2. 队列里有没有收到任务？
3. Worker 能不能正常处理？
4. GET 查询订单状态 → 是否正常？
5. Polling 是否还能用？
6. 下载功能是否正常？

如果有任何功能坏了，告诉我是哪里出了问题。
```

**每确认一步可以run，立刻 commit：**

```jsx
git add .
git commit -m "restructure: "
git push
```

---

## 关于这个章节需要学到什么程度

不需要能自己手写出这个拆分。但是你需要能回答：

1. 打开任意一个文件（比如 services.py），能说出来这个文件负责什么
2. 如果面试官问"你想改 XXX，你去哪个文件改"，你能秒答
3. 能说出来为什么你这样拆（不是因为教科书说的，是因为你经历过不拆的痛苦）

**测试方式：** 问 AI 下面这些问题，看你能不能在 AI 回答之前自己说出来：

```jsx
请依次问我以下问题，每次只问一个，等我回答后告诉我对不对：

1. 如果你想改"返回给前端的数据格式"，你去改哪个文件？
2. 如果 LLM 调用的逻辑需要修改，你去改哪个文件？
3. 如果你想加一个新的 API 接口，你需要改哪些文件？
4. views.py 里应不应该出现数据库查询的代码（比如 Patient.objects.filter(...)）？
5. 如果你要加输入验证（比如检查 NPI 是不是 10 位数），你会加在哪个文件里？
```

---

## 面试考点

**Q: 你的项目代码是怎么组织的？**

`A: 分层架构。views 只管收发请求，serializers 做数据校验和格式转换，
   services 放业务逻辑。这样改一个地方不会影响其它地方。`

**Q: 你为什么不一开始就这样拆？**

`A: 一开始功能少，一个文件就够了，没必要过度设计。后面加了异步、队列、Polling，
   文件越来越大，改起来越来越怕出错，所以重构了一次。
   实际工作中也是这样，先跑起来，痛了再拆。`

**Q: 你怎么决定一段代码应该放在哪个文件里？**

`A: 看它在做什么。如果它在处理 HTTP 请求和响应 → views。
   如果它在做数据格式转换或校验 → serializers。
   如果它在做业务逻辑（调用外部服务、操作数据库） → services。
   如果拿不准，就想"如果我换了前端框架（React 换成 Vue），这段代码需要改吗？"
   如果不需要改，那它就不应该在 views 里。`

---

## Restructure 完成！

✅ 代码拆成了清晰的分层结构

✅ 理解了为什么要拆（不是因为教科书说要拆，是因为不拆活不下去）

✅ 功能没变，但代码好找多了

---

❓ 但是… 输入还是没有验证！用户可以输入任何东西。NPI 随便填个 abc 也能提交。

好消息是：现在你有了 serializers.py，校验逻辑天然就知道往哪放了。

👉 下一步我们加上输入验证和重复检测。

# Day 8: Error, Warning, Tests

> 🎯 今日目标
> 
> 
> 完成 Day 1 需求澄清中讨论的所有业务逻辑：输入验证、患者/订单/Provider 重复检测
> 
> **这一天的核心学习点：**
> 
> 1. **怎么写好的 AI prompt**
> 2. **Error 和 Warning 应该怎么设计**（通过体验痛点来理解）

---

### 面试考点：

今天的内容是一个非常好的bq答案。今天的内容不仅需要理解为什么这样做，还要能口头说出来怎么做出来的。（也就是不用能code出来，但是思路要能说出来）

## ⚠️ 今天的学习方式

今天没有新技术引入，都是业务逻辑实现。

---

## Part 1: 重复检测逻辑

## 1 业务规则回顾（Day 1 已确认）

| 场景 | 处理方式 | 原因 |
| --- | --- | --- |
| **Provider**: NPI 相同 + 名字相同 | 复用现有 | - |
| **Provider**: NPI 相同 + 名字不同 | ❌ 阻止 | NPI 是国家执照号，全国唯一 |
| **Patient**: MRN 相同 + 名字DOB相同 | 复用现有 | - |
| **Patient**: MRN 相同 + 名字或DOB不同 | ⚠️ 警告 | 可能是录入错误 |
| **Patient**: 名字+DOB相同 + MRN不同 | ⚠️ 警告 | 可能是同一人 |
| **Order**: 同患者 + 同药物 + 同一天 | ❌ 阻止 | 肯定是重复提交 |
| **Order**: 同患者 + 同药物 + 不同天 | ⚠️ 警告 | 可能是续方 |

## 2 让 AI 实现

**🤖 好的 prompt**

```jsx
请帮我实现重复检测逻辑。

技术栈：Python + Django ORM

模型：
- Provider: name, npi (unique)
- Patient: first_name, last_name, mrn (unique), date_of_birth
- Order: patient (FK), medication_name, created_at

业务规则：

Provider 检测：
- NPI 相同 + 名字相同 → 复用现有
- NPI 相同 + 名字不同 → 必须阻止（NPI 是国家执照号，全国唯一）

Patient 检测：
- MRN 相同 + 名字和DOB都相同 → 复用现有
- MRN 相同 + 名字或DOB不同 → 警告
- 名字+DOB 相同 + MRN 不同 → 警告

Order 检测：
- 同一患者 + 同一药物 + 同一天 → 必须阻止
- 同一患者 + 同一药物 + 不同天 → 警告（如果用户传了 confirm=True 则跳过）

不需要统一格式处理， 不需要有base error class，只是简单的需要抛出error就抛出就好，
可以用if else处理各种error，我之后会有专门的class 来处理，现在我就想看看不处理这个code能有多复杂
```

现在重点看看error和warning是怎么实现的。重点看这个：

prompt：

```jsx
你刚才的Error 和Warning是怎么handle的？

有出现这些问题吗？
- 每个 View 里都写 if-else 返回不同的 Response
- 返回格式不统一（有的用 error，有的用 warning，有的用 msg）
- 状态码不统一（有的 400，有的 409）
```

### 想一下：你的项目里有几种"不正常"的情况？

想一分钟。

其实就三种：

| 类型 | 例子 | 该怎么处理 |
| --- | --- | --- |
| **输入格式不对** | NPI 填了 abc，MRN 不是 6 位数 | 直接打回去，400 |
| **业务规则阻止** | 同一 NPI 对应了不同名字的 Provider | 不让提交，409 |
| **业务警告** | 可能是重复的患者，但不确定 | 提醒用户，让用户确认后可以继续 |

这三种东西，如果每个都自己写一套格式，前端就疯了——拿到一个响应，不知道该按什么格式解析。

---

### 解决办法：一个 base class 统一所有错误的格式

```
BaseAppException          ← 所有错误的基类，定义"一个错误长什么样"
├── ValidationError       ← 输入格式不对（NPI不是10位）
├── BlockError            ← 业务规则阻止（NPI冲突）
└── WarningException      ← 业务警告（可能重复）
```

BaseAppException 定义的是：每一个错误都必须有 type、code、message、detail。所有子类继承它，只需要填自己的具体内容。

然后写一个统一的 exception_handler：它只认识 BaseAppException 一个类。不管你抛出的是 ValidationError、BlockError 还是 WarningException，handler 拿到的都是同一个格式，统一转成 JSON 返回给前端。

前端也只需要认识一个json格式：

```jsx
{
  "type": "block / warning / validation",
  "code": "DUPLICATE_NPI",
  "message": "该NPI已存在但名字不同",
  "detail": { ... }
}
```

**View 里面只需要 raise，不用关心返回格式。所有格式由 handler 统一处理。**

## Part 2: Error 和 Warning 的设计

> 🎯 这是今天最重要的内容
> 
> 
> 在真实项目中，错误处理是区分初级和中级工程师的关键点。
> 
> 目的是要知道 error要有一个专门的class来handle，就够了。
> 

---

**🤖 好的 prompt**

```
请帮我设计统一的错误处理系统。

我的项目有三种"不正常"的情况：
1. 验证错误（Validation Error）：用户输入格式不对（NPI不是10位、MRN不是6位）
   - 由 serializer 检查
   - 返回 400

2. 业务阻止（Block）：业务规则不允许（同一NPI对应不同名字的Provider）
   - 由重复检测逻辑检查
   - 返回 409

3. 业务警告（Warning）：可能有问题但允许用户确认后继续（可能是重复患者）
   - 由重复检测逻辑检查
   - 返回 200 但带 warnings 字段

请帮我设计：
1. 一个 BaseAppException 基类，定义统一的错误格式（type, code, message, detail, http_status）
2. 三个子类继承 BaseAppException：ValidationError, BlockError, WarningException
3. 一个统一的 exception_handler，只认识 BaseAppException，统一转成 JSON
   - View 里只需要 raise，不用关心返回格式
   - 所有错误格式统一，由 exception_handler 处理
   - 要改格式？只改一个地方
4. settings.py 配置
5. 同时兼容 DRF 自带的 ValidationError（serializer 抛出的）

我要的效果是：前端拿到任何响应，都能用同一套逻辑判断"成功了还是失败了，
如果失败了是什么类型的失败"。不需要一个个 if-else 判断。
```

---

这里可以参考这个视频。把github code给ai 让ai对比一下github里怎么做的，

如果不是claude付费用户，可以zip这个repo 然后给ai

https://www.xiaohongshu.com/discovery/item/6976d5c7000000000a02ef93?app_platform=ios&app_version=9.19.1&share_from_user_hidden=true&xsec_source=app_share&type=video&xsec_token=CBjv4qdDlSqJMvwPq1rg8pINJ_eyI4c_uaZJg0KDib5H4=&author_share=1&xhsshare=WeixinSession&shareRedId=ODpGM0VLNDw2NzUyOTgwNjZFOTdGNUlL&apptime=1769823896&share_id=0d29b17112f94c3ea0e5aa2760c0c596

## Part 3: Tests

### 🤖 好的 prompt

```
1. 我现在要加上unit test 和integration tests. 
2. 请帮我为 Patient 重复检测写 pytest 测试。要90%Unit test coverage. 
3. 帮我加上integration test
4. 加上之前的error test，确保错误的输入会生成对应的error 
5. 我要用docker 来run这些tests

```

## 面试问题

时，面试官经常问："你怎么处理错误？"

这个也是很多学生做intern的时候会做的活，就是因为大公司在最开始的时候没有做统一的error handle管理,所以到后面越来越多的error散落在各种文件里面。（可以变成一个bq故事）

[BQ：Error 系统](https://www.notion.so/BQ-Error-2f773b2e0063806fad6efcbfc16d3d8d?pvs=21)

## Day 8完成！

✅ 学会了自定义 Exception 的设计

✅ 理解了 ERROR vs WARNING 的区别

✅ 加上了测试

❓ 但是… 如果有多个数据来源，格式都不一样怎么办？

👉 明天我们引入反腐层（ACL）来处理这个问题。

# Day 9: 重构 - 用 Adapter Pattern 处理多数据源

**🎯 今日目标（内容很多，可以分成两天来做）**

把你 OOD 课上学的 Adapter Pattern 用到真实场景里。

这也是为什么后端程序员的技术比较通用——你加入新工作后，基本就是在 call 别人的 API，或者被别人 call。你的上游数据格式乱七八糟，但你的内部逻辑需要干净统一。这个也是我自己在工作中作为后端程序员每天在干的活。

我们会先根据上游数据格式乱七八糟来体验。我们会根据每一种格式来写一种处理办法，我们先体验一下这个痛苦的过程。

## **1 背景**

目前你的系统只允许 CVS 的工作人员通过 web form 输入数据来生成 care plan。

PM 找到你说：

> "我们要开放 API 让其他医疗机构也能接入我们的系统。一方面可以扩大用户群，另一方面这些数据可以用于后续大模型的调参和训练。
> 
> 
> 现在有三家机构想接入：
> 
> - **CVS 内部**：继续用现有的 web form（你之前做的）
> - **小型诊所：**发送JSON格式
> - **PharmaCorp**：一家药企，他们的系统发 XML 格式

---

**数据源 A：小型诊所（JSON格式）**

[Json 格式](https://www.notion.so/Json-2fa73b2e006380f980e5c2469f4cebb2?pvs=21)

---

**数据源 B：合作药企（正式的 XML 转成 dict）**

[xml](https://www.notion.so/xml-2fa73b2e0063800e8152f17c6d0a989f?pvs=21)

---

## **2 练习 1：分别处理每个数据源（60 分钟）**

就用最直接的方式，写两个函数处理这两个数据源。

**任务**：

- **验证数据**：NPI 必须 10 位、MRN 必须 6 位、ICD-10 格式要对
- **重复检测**：之前做过的 patient/provider 重复检测逻辑
- 调用 LLM 生成 care plan

**要求**：先写完，可以适当vibe coding，但是在file里，comment要分别自己写出来，再让ai补全code。不要跳过这一步！

## **3 写完后，回答这些问题**

1. 你复制粘贴了多少代码？
2. 验证逻辑写了几遍？
3. 重复检测逻辑写了几遍？
4. 如果验证规则要改（比如 MRN 从 6 位改成 8 位），你要改几个地方？
5. 如果 LLM prompt 要调整，你要改几个地方？
    
    

没有统一格式的话，是否每个数据源都要写一遍验证、一遍存储、一遍重复检测，但是其实这些logic是一致的, 只是命名不一致，所以才需要单独处理每一个。

现在想象一下,有没有什么办法可以解决刚才的问题? **说白了刚才的问题是不是出自于每一个公司都有自己的命名系统以及自己的格式系统?** 如果我们能把每一个命名系统都转化为我们的命名系统,是不是我们的service层, 也就是business处理层, 就只需要一个了? 这样我们就只需要处理每一个文档的转换就可以了？这个就是Adapter Pattern。

即便没有这样的定义, 即便没有人告诉你叫什么名字, 你是不是也想这样做了? 

AI：

```jsx

我需要设计一个adapter来处理多数据源。

业务场景：
- 我们接收来自不同医院/诊所的订单
- 每个来源的数据格式不同（有的 JSON，有的 XML）
- 字段命名也不同（有的用 fname，有的用 first_name，有的用 PatientFirstName）

技术栈：Python + Django

请帮我设计：

1. InternalOrder dataclass（内部标准格式）
   - 包含：patient, provider, careplan 等
   - 这是业务逻辑唯一认识的格式

2. BaseIntakeAdapter 抽象基类
   - parse(): 解析原始数据
   - transform(): 转换成 InternalOrder
   - validate(): 验证转换后的数据

3. 一个具体的 Adapter 示例（比如 ClinicBAdapter）
   - 展示怎么把外部格式转成 InternalOrder

4. 工厂函数 get_adapter(source: str)
   - 根据来源返回对应的 Adapter

要求：
- 新增数据源时只需要加一个 Adapter，不改业务代码
- 保留原始数据用于排查问题
```

## 4 新增来源时

```jsx
现在你已经把这个写好了,能不能给我一个新的医院,用新的data format,新的命名,
让我体验一下,加入一个新的医院的时候, 怎么加入，给我一个新的不同的文档格式，不同的命名
```

# Day 10: 重构 - 用 Adapter Pattern 处理多数据源

## 1 LLM Service 也可以用同样的模式

如果以后要切换 LLM（OpenAI → Claude → 其他），同样的模式：

```jsx
OpenAIService   ──┐
                  │
ClaudeService   ──┼──→  BaseLLMService  ──→  业务逻辑
                  │
LocalLLM        ──┘
```

照猫画虎，这里自己code一下看自己会怎么做。会有哪些file，每个file里面有什么class，每个class里面有什么method，再把每个method的下面写一些comments，比如说自己将会实现什么function。然后让AI根据comments 判断是不是一个好的实现运用adapter的方式。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

。

### 🤖 好的 prompt

```jsx
请帮我设计 LLM Service 的抽象层。

需求：
- 现在用 OpenAI，以后可能换成 Claude 或本地模型
- 业务代码不应该知道具体用哪个 LLM

请设计：
1. BaseLLMService 抽象基类
2. OpenAIService 和 ClaudeService 实现
3. 工厂函数根据配置返回对应的 Service
```

---

## 2 面试怎么说

> Q: “你怎么处理多个数据来源？”
> 
> 
> **A:** “我用了 Adapter模式。我们定义了内部的标准数据结构 InternalOrder，每个外部来源有一个 Adapter 负责把外部格式转换成内部格式。这样业务逻辑不用关心数据从哪来、什么格式。新增数据源只需要加一个 Adapter，不用改业务代码。”
> 

---

## Day 10 完成！

✅ 学会了如何设计可扩展的架构

✅ 知道新增数据源不需要改业务代码

❓ 但是… 这么公司接入，我们又接入这么多的large language model，万一哪里出错,我怎么知道? ？

👉 明天我们加上监控。

# Day 11: 监控 - Prometheus + Grafana

> 🎯 今日目标
> 
> 
> 配置监控系统，让你能主动发现问题。
> 
> **面试面什么?**
> 
> **其实这个地方并不是并不会让一个Intern 或者 NewGrad自己设计一个monitor, 因为公司是一定会有monitor的系统的,** 但你知不知道monitor是什么? monitor什么东西? 以及会不会用这个来debug。
> 
> 不需要你知道完全设计出来要monitor哪些东西, 这个不在考察范围内。但是你在工作的时候又一定会遇到，所以提到一些名词的时候，你要知道面试官在讲什么就行。
> 

---

## 1 为什么需要监控？

系统上线后，你怎么知道它运行正常？怎么发现问题？

| 没有监控 | 有监控 |
| --- | --- |
| 用户投诉才知道出问题 | 主动发现问题 |
| 不知道哪里慢 | 看到具体瓶颈 |
| 出问题后盲目排查 | 直接看 Dashboard 定位 |

---

## 2 应该监控什么？

### 几个真实场景

### 场景 1：周一早上的噩梦

周一早上 9 点，你刚到公司，老板发消息：

> "系统挂了，CVS 那边打电话来投诉，说从早上 7 点就用不了了。"
> 

你打开电脑，看了一下服务器... 确实挂了。但你不知道：

- 是 7:00 挂的还是 6:30 就挂了？
- 挂之前有什么异常？
- 是内存爆了？CPU 100%？还是数据库连不上？

你只能盲目地看 log，花了 2 小时才定位到问题。

---

### 场景 2：用户说"很慢"

PM 转发了一封 CVS 的邮件：

> "你们的系统最近很慢，生成一个 care plan 要等 30 秒。"
> 

你在本地测了一下，3 秒就好了啊？你不知道：

- 是所有用户都慢，还是只有某些用户慢？
- 是一直慢，还是某些时间段慢？
- 慢在哪里？是 LLM API 慢？数据库查询慢？还是网络慢？

---

### 场景 3：LLM 费用暴涨

月底财务找你：

> "这个月 OpenAI 的账单比上个月多了 5 倍，你们是不是有 bug？"
> 

你不知道：

- 每天调用了多少次 LLM？
- 平均每个请求用了多少 token？
- 是某一天突然暴涨，还是慢慢涨上去的？
- 是不是有人在刷你的 API？

---

### 1. 如果有监控，你会想看到什么？

根据上面的场景，想一想：

**场景 1（系统挂了）**：你希望能看到什么数据，让你快速定位问题？

**场景 2（系统慢）**：你希望能看到什么数据，让你知道慢在哪里？

**场景 3（费用暴涨）**：你希望能看到什么数据，让你知道钱花在哪里？

**场景 4（半夜出问题）**：你希望系统能自动做什么？

先自己想 5 分钟，再往下看。

。

。

。

。

。

### 2. 针对我们的 Care Plan 系统，应该监控什么？

想一想我们系统的关键路径：

`用户请求 → API 服务器 → 数据库查询 → LLM 调用 → 返回结果`

每一步都可能出问题。你会监控哪些指标？

**提示**：

- API 层面：请求量、响应时间、错误率
- LLM 层面：调用次数、延迟、token 用量、失败率
- 业务层面：每天生成多少 care plan、重复检测触发了多少次

---

## 3 Prometheus + Grafana 是什么？

定义不重要，你实现出来后直观就能看到。

- **Prometheus**：收集和存储指标数据
- **Grafana**：可视化仪表盘

```jsx
┌─────────────┐     拉取指标     ┌─────────────┐
│   Django    │ ◀─────────────── │ Prometheus  │
│   (应用)    │                  │  (收集器)   │
└─────────────┘                  └──────┬──────┘
                                        │
                                        │ 查询
                                        ▼
                                 ┌─────────────┐
                                 │   Grafana   │
                                 │  (可视化)   │
                                 └─────────────┘
```

---

## 4 动手做

```jsx
我有一个医疗 care plan 生成系统，需要设计监控方案。
请帮我：
1. 列出需要监控的指标，分成四类：业务指标、性能指标、错误指标、资源指标
2. 每个指标说明它能帮我发现什么问题
3. 建议告警阈值（如果需要告警的话）
4. 用表格形式输出
```

```jsx
我想用 Prometheus + Grafana 做监控。
怎么run？怎么连接Prometheus + Grafana？
我用docker，怎么跑？
```

---

## Day 11 完成！

✅ 有监控了，能主动发现问题

不需要你知道完全设计出来要monitor哪些东西, 这个不在考察范围内。但是你在工作的时候又一定会遇到，所以提到一些名词的时候，你要知道面试官在讲什么就行。

---

# Day 12: 熟悉 AWS Console

## ⚠️ 费用提醒（重要！先看这里）

**AWS 不是完全免费的，练习前请注意：**

| 服务 | 免费额度 | 超出后 |
| --- | --- | --- |
| Lambda | 每月 100 万次请求免费 | 基本用不完，不用担心 |
| SQS | 每月 100 万次请求免费 | 基本用不完，不用担心 |
| RDS | 新账号首年每月 750 小时免费（db.t3.micro） | 超出后按小时收费 |
| API Gateway | 每月 100 万次请求免费 | 基本用不完 |

**关键提醒：**

`1. RDS 是最容易花钱的
   - 即使没人用，只要开着就收费
   - 练习完记得删掉！

2. 用完记得删除所有资源
   - 不删除会一直扣费
   - Day 12 结尾有删除指南

3. 建议设置 Budget Alert
   - AWS Console → Billing → Budgets
   - 设置超过 $5 就发邮件提醒`

---

## 1 今天的目标

**不碰本地代码，纯粹在 AWS Console 上练习。**

但是不要一次学所有东西。我们一个一个来，每一步都先成功一次，再加下一个。

```jsx
10.0  Lambda 能跑                     ← 先搞一个最小的成功
10.1  浏览器能访问 Lambda              ← 加一个 API Gateway
10.2  数据库能用                       ← 单独创建 RDS
10.3  Lambda 能连数据库                ← 把它俩连起来
10.4  SQS 能发消息                     ← 单独玩 SQS
10.5  SQS 能触发 Lambda               ← 把它俩连起来
10.6  全部连起来                       ← 串成完整流程
```

---

## 2 先理解：SQS 和 Lambda 是什么

**SQS 是什么？**

```jsx
和Redis 队列一样存消息。

区别：
- Redis：等着别人来拿
- SQS：主动给 Lambda 送过去
```

**Lambda 是什么？**

```jsx
跑代码的，是一个python/ javascirpt （不管什么语言）的脚本

区别：
- Celery Worker：主动去 Redis 拿任务
- Lambda：被动等着，SQS 送过来就处理
```

**一句话总结：**

```jsx
本地：Celery 主动找 Redis 拿
AWS：SQS 主动给 Lambda 送

记住这些就够了。
所以 Lambda 不用一直跑着等，有任务才启动，省钱。
```

**本地 vs AWS 对照表：**

| 本地 | AWS | 作用 |
| --- | --- | --- |
| Redis | SQS | 消息队列 |
| Celery Worker | Lambda | 处理任务 |
| PostgreSQL | RDS | 数据库 |
| Django | EC2 + API Gateway | 接收用户请求 |

---

## 3 练习

今天的练习全在 AWS 页面，不需要写代码。可以使用 ChatGPT Atlas 浏览器帮你操作。

---

### 1. 先搞一个最小的成功：Lambda

在学任何架构之前，先做一件事：**让一段代码跑在 AWS 上。**

🤖 Prompt：

```jsx
我完全没用过 AWS Lambda。

请带我做最简单的一个练习：
1. 创建一个 Lambda 函数，代码就一行：返回 "hello world"
2. 在 Lambda 控制台点 Test，能看到 "hello world"

只做这一步，不要连数据库，不要连 SQS，什么都不要连。
```

**✅ 验证：Lambda 控制台点 Test → 看到 "hello world"**

就这样。这就是 Lambda。就是一个函数，跑在亚马逊的机器上而已。

---

### 2. 让外面的人也能访问：API Gateway

刚才你的 Lambda 能跑了，但只能在 AWS 控制台里点 Test。别人访问不了。

现在给它加一个门——让你在浏览器里也能看到结果。

**先问 AI 需要什么：**

🤖 Prompt：

```jsx
我已经有一个 Lambda 函数，能返回 "hello world"。

现在我想在浏览器里访问它。
在我开始之前，请先告诉我需要什么、需要配置什么、有哪些容易踩的坑。
先不要给我具体步骤，我想先了解全貌。
```

了解完之后：

```jsx
好的，现在请一步一步带我配置。
```

**✅ 验证：浏览器输入 URL → 看到 "hello world"**

你本地跑 Django 的时候访问 `localhost:8000`，代码在你自己电脑上。现在访问 AWS 给的这个 URL，代码在亚马逊的机器上。就这个区别。

---

### 3. 数据库：RDS

现在你的 Lambda 只会说 hello world。让它干点正事——但是先得有个数据库。

🤖 Prompt：

```jsx
我想在 AWS 上创建一个 PostgreSQL 数据库（RDS）。
用免费套餐，数据库名叫 careplan。

在我开始之前，请先告诉我需要什么、有哪些要注意的。
先不要给我具体步骤。
```

了解完之后：

```jsx
好的，现在请一步一步带我创建。
```

**✅ 验证：RDS 实例状态显示 "Available"**

---

### 4. 让 Lambda 连上数据库

现在你有一个 Lambda，也有一个数据库。让它们连起来。

**这一步坑最多。** 所以一定要先问清楚需要什么。

🤖 Prompt：

```jsx
我想让 Lambda 函数连接 RDS PostgreSQL 数据库。

在我开始配置之前，请先告诉我：
1. 需要哪些前置条件？
2. 需要配置哪些东西（网络、权限、依赖等）？
3. 有哪些常见的坑？

先不要给我具体步骤，我想先了解全貌。
```

AI 会告诉你需要 VPC、安全组、IAM 权限、psycopg2 依赖库这些东西。**不需要背，但你要知道有这些东西存在。**

了解完之后：

```jsx
好的，现在请一步一步带我配置。
Lambda 的功能：接收 patient name 和 medicine name，存到数据库。
```

**✅ 验证：Lambda 控制台点 Test → 去 RDS 查 → 数据存进去了**

---

### 5. 消息队列：SQS

到这一步先忘掉 Lambda 和数据库。**单独玩一下 SQS。**

🤖 Prompt：

```jsx
我想在 AWS 上创建一个 SQS 队列，名字叫 order-queue。

请告诉我：
1. 怎么创建
2. 怎么手动发一条消息
3. 怎么在控制台查看这条消息
```

**✅ 验证：手动发一条消息 → 在控制台能看到这条消息**

这个时候你去看，消息还在队列里，因为没有人取走它。**记住这个感觉，下一步会不一样。**

---

### 6. 让 SQS 触发 Lambda

现在把 SQS 和 Lambda 连起来。

**先别急着动手：**

🤖 Prompt：

```jsx
我想让 SQS 队列触发一个 Lambda 函数。

在我开始配置之前，请先告诉我：
1. 需要哪些前置条件？
2. 需要配置哪些权限？
3. 有哪些容易踩的坑？

先不要给我具体步骤，我想先了解全貌。
```

了解完之后：

```jsx
好的，现在请一步一步带我配置。
```

**⚠️ 重要：配置完之后，你再往 SQS 发一条消息试试。**

发完之后去 SQS 控制台看——**消息没了。**

**不要慌。这不是出错了。**

在 10.4 的时候，你往 SQS 发消息，消息一直待在那里，因为没人拿。现在你连了 Lambda，SQS 一收到消息就立刻送给 Lambda 处理，处理完消息就自动删除了。

所以你不能再去 SQS 控制台看结果了。**你要去 CloudWatch Logs 看。** Lambda 每次运行都会在 CloudWatch 留下日志。

🤖 Prompt：

```jsx
我往 SQS 发了消息，但在 SQS 控制台看不到了。
我怎么确认 Lambda 确实被触发了？请告诉我怎么看 CloudWatch 日志。
```

**✅ 验证：往 SQS 发消息 → SQS 里消息消失了 → 去 CloudWatch 看 → Lambda 的日志在那里**

**这就是 SQS 和 Redis 最大的区别：SQS 会主动触发 Lambda，消息被处理后自动消失。**

---

### 7. 全部连起来

到这一步你已经：

```jsx
✅ Lambda 能跑了                    
✅ 浏览器能访问 Lambda 了            
✅ 数据库能存数据了                  
✅ SQS 能发消息了                   
✅ SQS 能自动触发 Lambda 了          
```

每一块都单独成功过了。现在把它们串起来。

需要再创建一个 Lambda 来查数据。

🤖 Prompt：

```jsx
我现在有：
- 一个 RDS 数据库
- 一个 SQS 队列
- 一个 Lambda（create_order，被 SQS 触发，往数据库写数据）

我还需要：
- 一个新的 Lambda（get_orders，从数据库查数据并返回）
- API Gateway 配置两个路由：
  - POST /orders：往 SQS 发消息
  - GET /orders：调用 get_orders Lambda

请一步一步带我完成。
```

**✅ 验证：**

```jsx
Postman 发 POST /orders
  → SQS 收到消息
  → Lambda 被触发
  → 数据存到 RDS
  → 浏览器访问 GET /orders
  → 看到刚才存的数据
```

---

## 4 架构

走到这里再看这张图，每一块你都亲手碰过了：

```jsx
   ┌─────────────────────────────┐
   │      Postman / 浏览器        │
   └──────┬──────────────▲───────┘
          │              │
          │ POST /orders │ GET /orders
          ▼              │
┌──────────────────────────────────────────────────────────────┐
│                            AWS                                │
│                                                               │
│                      ┌─────────────┐                         │
│                      │ API Gateway │          │
│                      └──────┬──────┘                         │
│                             │                                │
│              ┌──────────────┴──────────────┐                 │
│              ▼                             ▼                 │
│        ┌───────────┐                 ┌───────────┐           │
│        │  Lambda   │                 │  Lambda   │           │
│        │ 发到SQS    │                 │ 查询订单   │           │
│        └─────┬─────┘                 └─────┬─────┘           │
│              │                             │                 │
│              ▼                             ▼                 │
│        ┌───────────┐                 ┌───────────┐           │
│        │    SQS    │                 │    RDS    │           │
│        └─────┬─────┘                 └───────────┘           │
│              │                             ▲                 │
│              │ 自动触发                     │                 │
│              ▼                             │                 │
│        ┌───────────┐                       │                 │
│        │  Lambda   │───────────────────────┘                 │
│        │ 创建订单   │                                         │
│        └───────────┘                                         │
│                                                               │
└──────────────────────────────────────────────────────────────┘
```

---

⚠️ 注意：RDS 开着会花钱！如果今天不继续下一天的内容，建议全部删除。明天再重新创建。

关于收费，有问题可以给 AWS 的官方客服打电话，这些钱都是能返回回来的。不管是忘记了还是什么，都可以。

---

## Day 12 完成！

✅ 熟悉了 AWS Console 界面

✅ 理解了 SQS、Lambda、RDS、API Gateway 怎么配合

✅ 体验了"SQS 自动触发 Lambda"

✅ 知道了去 CloudWatch 看日志

✅ 每一块都单独验证过，不是一次性全塞进去的

❓ 但是... 这只是练习，怎么把自己的项目部署上去？

👉 明天把本地代码改成 AWS 版本，部署完整项目

# Day 13: 把本地代码部署到 AWS

## 1 回顾：昨天做了什么，今天做什么

**昨天：**

```jsx
在 AWS Console 上练习，熟悉了：
- Lambda 就是一个跑在 AWS 上的 Python 脚本
- SQS 是消息队列，会自动触发 Lambda
- RDS 是数据库
- API Gateway 让浏览器能访问 Lambda

用的是 hello world 级别的简单代码，不是我们的项目代码。
```

**今天和明天：**

```jsx
把我们真正的 CarePlan 项目部署到 AWS。

昨天的 hello world → 换成真正的代码。
每写一个 Lambda，立刻上传测试，确认能跑，再写下一个。
```

---

## 2 先想清楚：需要几个 Lambda？

回忆一下我们本地的架构：

```jsx
用户提交 → Django 接收 → 存数据库 → Celery 异步调 LLM → 更新数据库
用户查询 → Django 接收 → 查数据库 → 返回结果
```

现在要搬到 AWS，Django 没了，Celery 没了。**每个"动作"变成一个 Lambda。**

想一分钟：需要几个 Lambda？每个干什么？

。

。

。

。

。

```jsx
三个：

1. 创建订单 → 接收请求、验证、存数据库、发消息到 SQS
2. 生成 CarePlan → 被 SQS 触发、调 LLM、更新数据库
3. 查询订单 → 接收请求、查数据库、返回结果
```

| Lambda | 谁触发它 | 它做什么 | 它的下游是谁 |
| --- | --- | --- | --- |
| 创建订单 | API Gateway（用户点提交） | 验证、存数据、发 SQS | SQS |
| 生成 CarePlan | SQS（自动触发） | 调 LLM、更新数据库 | RDS |
| 查询订单 | API Gateway（用户查结果） | 查数据库、返回 | 用户 |

---

## 3 核心逻辑不用重写

本地代码里，调用 LLM 的逻辑、验证的逻辑、数据库操作的逻辑——这些都已经写好了。

搬到 AWS 不是重写，是**换一个入口**。

```jsx
本地：Django View → 调用你的核心逻辑
AWS：Lambda Handler → 调用同样的核心逻辑

核心逻辑不用改，只是"谁来调用它"变了。
```

🤖 Prompt：

```jsx
我的 CarePlan 项目现在是本地用 Django + Celery + Redis 跑的。
我想部署到 AWS，用 Lambda + SQS 替代。

我希望核心逻辑只写一份，本地和 AWS 都能用。

请先告诉我代码结构应该怎么组织，然后帮我整理。
```

---

## 4 第一个 Lambda：查询订单

**从最简单的开始。** 查询订单只做一件事：查数据库，返回结果。没有 SQS，没有 LLM，最不容易出错。

### 4.1 写代码

🤖 Prompt：

```jsx
我要写第一个 Lambda：查询订单状态和 CarePlan 内容。
它由 API Gateway 触发，复用之前的数据库查询逻辑。

请先告诉我需要注意什么，然后给我完整的代码。
```

### 4.2 打包上传

🤖 Prompt：

```jsx
我写好了这个 Lambda 的代码，现在要上传到 AWS。
代码里用到了一些依赖库。

请先告诉我怎么打包上传，有什么需要注意的。
```

### 4.3 配置环境变量

你的 Lambda 需要知道数据库地址。**这些不能写死在代码里。**

为什么？你的代码要放到 GitHub 上对吧？如果你把数据库密码直接写在代码里：

```jsx
# 千万别这样写
DB_PASSWORD = "mypassword123"
```

你一 push 到 GitHub，全世界都能看到你的密码。有人拿你的数据库密码直接连你的数据库，病人数据全泄露了。

**这不是夸张，GitHub 上每天都有人不小心提交密钥，几分钟内就会被扫描到。**

另外：你本地的数据库地址和 AWS 上的数据库地址不一样。写死了每次切换环境都要改代码。

🤖 Prompt：

```jsx
我的 Lambda 需要连接数据库，但配置信息不能写死在代码里。
请告诉我怎么配置环境变量，代码里怎么读取。
```

### 4.4 测试

在 API Gateway 配置 GET /orders/{id} → 连到这个 Lambda

**✅ 验证：浏览器访问 GET /orders/1 → 看到数据库里的订单数据**

如果出错了，不要猜，去 CloudWatch 看日志：

🤖 Prompt：

```jsx
我的 Lambda 报错了，我想看日志排查问题。
请告诉我怎么在 CloudWatch 里找到这个 Lambda 的日志。
```

我们已经看过一次 CloudWatch 日志。这次是一样的，只是换了一个 Lambda。

**之后每一步的"如果出错"都是同一个套路：去 CloudWatch 看日志。**

```jsx
在 API Gateway 配置 GET /orders/{id} → 连到这个 Lambda
```

**✅ 验证：浏览器访问 GET /orders/1 → 看到数据库里的订单数据**

如果出错，去 CloudWatch 看日志排查。

---

## 5 第二个 Lambda：创建订单

第一个能跑了，现在做第二个。这个稍微复杂一点——要存数据库，还要发消息到 SQS。

### 5.1 写代码

🤖 Prompt：

```jsx
我要写第二个 Lambda：创建订单。
它由 API Gateway 触发，需要复用之前的验证逻辑和数据库操作。
验证通过后，还要往 SQS 发一条消息。

请先告诉我需要注意什么，然后给我完整的代码。
```

### 5.2 打包上传 + 配置环境变量

打包上传跟上一个一样的流程。

但这个 Lambda 比上一个多做了一件事：**往 SQS 发消息。** 那它怎么知道往哪个 SQS 发？

就像你寄快递要写地址一样，Lambda 要往 SQS 发消息，就需要知道 SQS 的"地址"——就是 SQS 队列的 URL。

这个 URL 也不能写死在代码里，原因跟数据库密码一样：你本地测试用的 SQS 和 AWS 上的 SQS 地址不一样，写死了切换环境就出问题。

🤖 Prompt：

```jsx
这个 Lambda 除了数据库配置，还需要知道往哪个 SQS 队列发消息。
请告诉我怎么加上 SQS 队列 URL 的环境变量。
```

### 5.3 测试

```jsx
在 API Gateway 配置 POST /orders → 连到这个 Lambda
```

**✅ 验证：Postman 发 POST /orders → 返回"收到了，订单号是 xxx" → 去数据库查 → 数据存进去了 → 去 SQS 看 → 消息发出去了**

⚠️ 如果你在 Day 12 已经配了 SQS 触发 Lambda，这条消息可能已经被消费掉了，在 SQS 控制台看不到。去 CloudWatch 确认。

---

# Day 14: Dead Letter Queue

## 6 第三个 Lambda：生成 CarePlan

这是最核心的一个——调用 LLM 生成 CarePlan。而且它不是被 API Gateway 触发的，是被 **SQS 触发的**。

### 6.1 写代码

🤖 Prompt：

```jsx
我要写第三个 Lambda：生成 CarePlan。
它由 SQS 触发，不是由 API Gateway 触发的。
需要复用之前调用 LLM 的逻辑。

请先告诉我 SQS 触发跟 API Gateway 触发有什么不一样，
然后给我完整的代码。
```

### 6.2 打包上传 + 配置环境变量

打包上传跟前两个一样。

这次多了一个配置：LLM 的 API Key。这比数据库密码更敏感——有人拿到你的 API Key 就能用你的钱调 LLM。

🤖 Prompt：

```jsx
这个 Lambda 还需要 Claude/OpenAI 的 API Key。
这种敏感信息有没有比环境变量更安全的方式？
```

**✅ 验证：Lambda 控制台 → 看到 generate_careplan 函数 → 代码已上传 → 环境变量配好了**

### 6.3 配置 SQS 触发 Lambda（⚠️ 先理解重试机制）

在连接之前，先理解一个重要的机制。

**SQS 怎么知道消息有没有被成功处理？**

SQS 把消息发给 Lambda 之后，不是发完就忘了。它会等。

```jsx
SQS 发消息给 Lambda
  → Lambda 处理成功，返回正常 → SQS 说"好的"，删掉这条消息
  → Lambda 处理失败，报错了 → SQS 说"没处理好"，过一会儿再发一次
```

这个设计本身是合理的——万一网络抖了一下导致失败，SQS 自动帮你重试，不用你操心。

**但问题是：如果你的代码有 bug，每次处理都失败呢？**

```jsx
SQS 发消息 → Lambda 报错
  → SQS 过一会儿再发 → Lambda 又报错
  → SQS 再发 → Lambda 又报错
  → ……无限循环
```

Lambda 一直在跑，每次都花钱。如果你的 Lambda 还调了 LLM API，每次循环都在烧 API 费用。**放着不管一晚上，账单可能上百美元。**

**怎么防止？设置 Dead Letter Queue（DLQ）。**

DLQ 就是"失败队列"：一条消息如果失败超过 N 次（比如 3 次），SQS 就不再重试了，把它扔到 DLQ 里。你回头去 DLQ 看看是什么消息导致了失败，修好 bug 之后再处理。

**所以：先配 DLQ，再配触发器。顺序不能反。**

🤖 Prompt：

```jsx
我要配置 SQS 触发 Lambda，但我想先配好安全措施。
请告诉我：
1. 怎么给我的 SQS 队列配置 Dead Letter Queue
2. 设置最多重试 3 次，失败就进 DLQ
3. 配好 DLQ 之后，再配置 SQS 触发我的 generate_careplan Lambda
```

**✅ 验证：SQS 控制台 → 看到 DLQ 已配置 → 最大重试次数是 3 → 触发器连到了 Lambda**

### 6.4 测试

**先只发一条消息试试。** 不要一口气发好几条——万一有问题，一条好排查，十条就乱了。

🤖 Prompt：

```jsx
我已经配好了 SQS 触发 generate_careplan Lambda。
请告诉我怎么手动往 SQS 发一条测试消息，消息里包含一个订单 ID。
```

**✅ 验证：**

```jsx
往 SQS 手动发一条消息（包含订单 ID）
  → 去 CloudWatch 看 → Lambda 被触发了
  → 去数据库查 → CarePlan 生成了，状态变成 completed
```

如果 CloudWatch 里看到 Lambda 报错了，先去 SQS 控制台看看 DLQ 里有没有消息。有的话说明已经重试了 3 次都失败了，消息被安全地放到了 DLQ 里，不会无限循环。修好 bug 再重新处理就行。

### 6.5 自我探索：DLQ 里的消息怎么办？

消息进了 DLQ，说明处理失败了。但这些消息不能就这么放着不管——它们代表的是用户提交的订单，人家还在等 CarePlan 呢。

想一想：

- DLQ 里的消息你要怎么处理？
- 修好 bug 之后，怎么把 DLQ 里的消息重新处理？
- 你怎么知道 DLQ 里有消息了？能不能自动通知你？

🤖 Prompt：

```jsx
我的 SQS 配了 Dead Letter Queue。
如果有消息进了 DLQ，我应该怎么处理？
有没有办法在消息进入 DLQ 的时候自动通知我？
```

这个我们不做，了解就行。但面试如果聊到消息队列，能说出"我配了 DLQ，失败 3 次就不再重试，之后可以手动处理或者配告警"，就够了。

## 7 完整流程测试

三个 Lambda 都能跑了。现在从头到尾走一遍：

🤖 Prompt：

```jsx
我已经部署了完整的 CarePlan 系统到 AWS。
请告诉我怎么从头到尾测一遍，以及如果某一步出问题了怎么排查。
```

**✅ 验证：**

```jsx
Postman 发 POST /orders（提交订单）
  → 返回 "收到了，订单号是 xxx"

等几秒...

Postman 发 GET /orders/xxx（查询结果）
  → status: completed
  → 看到 CarePlan 内容
```

如果哪一步不对，去 CloudWatch 看是哪个 Lambda 出了问题。**因为你之前每个 Lambda 都单独测过了，所以你知道问题出在"串联"这一步，而不是某个 Lambda 本身。**

---

## 8 面试考点

**Q: 为什么要分成 3 个 Lambda，不写成 1 个？**

想一分钟。

。

。

。

。

。

```jsx
因为它们被不同的东西触发：
- 创建订单：被用户的 POST 请求触发
- 生成 CarePlan：被 SQS 消息触发
- 查询订单：被用户的 GET 请求触发

分开写，每个 Lambda 只做一件事，简单清晰。
```

**Q: 为什么全用 Lambda，不用 EC2？**

```jsx
Lambda 更省钱，没请求的时候不花钱。
而且不用管服务器，AWS 自动扩展。
```

---

## ⚠️ 费用提醒

| 资源 | 会花钱吗 |
| --- | --- |
| Lambda | 基本免费（每月 100 万次） |
| API Gateway | 基本免费（每月 100 万次） |
| SQS | 基本免费（每月 100 万次） |
| RDS | ⚠️ 开着就花钱 |
| CloudWatch | 基本免费 |

**如果不继续下一天的内容，建议删除 RDS，避免持续扣费。**

关于收费，有问题可以给 AWS 的官方客服打电话，这些钱都是能返回回来的。

---

## Day 14 完成！

✅ 把真正的 CarePlan 代码部署到了 AWS

✅ 3 个 Lambda 都单独测过 + 完整流程测过

✅ 每写一个就测一个，不是一次性全扔上去

❓ 但是... 这些 AWS 资源都是手动创建的，万一要重新搭一遍呢？

👉 明天用 Terraform 一键管理所有 AWS 资源

# Day 15: Terraform 一键部署

## 1 回顾：为什么要用 Terraform

**我们手动创建了这些资源：**

```jsx
RDS 数据库
SQS 队列
Lambda × 3
API Gateway
IAM 权限
环境变量配置
...
```

**手动创建的问题：**

| 问题 | 场景 |
| --- | --- |
| 不可重复 | 换个 AWS 账号，要重新点一遍 |
| 没有记录 | 配置都在控制台上，忘了怎么配的 |
| 团队协作难 | 新人加入，要手把手教怎么配置 |
| 灾难恢复难 | 资源被误删了，要记住怎么重建 |
| 环境不一致 | 测试环境和生产环境配置不一样 |

---

## 2 Terraform 是什么

**一句话：把 AWS 配置写成代码**

```jsx
手动创建：
  打开 AWS Console → 点 Lambda → 填配置 → 创建
  打开 AWS Console → 点 SQS → 填配置 → 创建
  ...

Terraform：
  写一个配置文件，描述你要什么资源
  运行 terraform apply
  Terraform 自动帮你创建所有资源
```

**这叫 Infrastructure as Code (IaC)：基础设施写成代码的样子**

---

## 3 今天的目标

```jsx
1. 先删除前3天手动创建的资源
2. 用 Terraform 重新创建所有资源
3. 验证：和手动创建的效果一样
4. 体验：terraform destroy 一键删除
```

**这样你能体验到：**

```jsx
手动创建：点了半天，还容易漏
Terraform：一个命令，全部创建好

手动删除：一个一个删，怕删错
Terraform：一个命令，全部删干净
```

---

## 4 第一步：删除手动创建的资源

**先把之前创建的资源删掉，等下用 Terraform 重建：**

🤖 Prompt：

```jsx
我在 AWS 上手动创建了这些资源：
- RDS 数据库
- SQS 队列（主队列 + Dead Letter Queue）
- Lambda 函数 × 3
- API Gateway
- IAM Role

请告诉我删除的顺序和步骤（有些资源有依赖关系）。
```

**删除顺序：**

```jsx
1. API Gateway（先删，因为它连着 Lambda）
2. Lambda 函数的 SQS 触发器
3. Lambda 函数
4. SQS 队列
5. RDS 数据库
6. IAM Role（最后删）
```

---

## 5 第二步：安装 Terraform

🤖 Prompt：

```jsx
我想在我的电脑上安装 Terraform。

请告诉我：
1. 怎么安装（Mac / Windows / Linux）
2. 怎么验证安装成功
3. 怎么配置 AWS 认证（让 Terraform 能操作我的 AWS 账号）
```

---

## 6 第三步：先写一个简单的例子

**先创建一个简单的资源，体验 Terraform 怎么工作：**

🤖 Prompt：

```jsx

我刚装好 Terraform，想先试一个简单的例子。

请帮我写一个 Terraform 配置文件：
1. 创建一个 S3 bucket（名字叫 my-test-bucket-12345）
2. 告诉我文件放哪里，叫什么名字
3. 怎么运行 terraform init / plan / apply
4. 怎么验证 S3 bucket 创建成功了
```

---

## 7 动手实现

### 7.1 先跑起来：只创建一个 SQS

不要一次写所有资源。先用 Terraform 创建最简单的一个东西，确认 Terraform 本身能跑。

🤖 Prompt：

```jsx
我完全没用过 Terraform。

请带我做最简单的一个练习：
1. 怎么安装 Terraform
2. 怎么配置 AWS 认证
3. 写一个最简单的 Terraform 文件：只创建一个 SQS 队列
4. 怎么运行 terraform init / plan / apply
5. 怎么去 AWS 控制台确认队列创建成功了
```

**✅ 验证：terraform apply → 去 AWS 控制台看 → SQS 队列出现了**

就这样。你用一行配置，Terraform 就帮你在 AWS 上创建了一个资源。Day 12 你是在控制台上手动点出来的，现在是用代码创建的。

---

### 7.2 加上 Dead Letter Queue

🤖 Prompt：

```jsx
我已经用 Terraform 创建了一个 SQS 队列。

现在我想加一个 Dead Letter Queue：消息处理失败 3 次就移到 DLQ。
请告诉我怎么改 Terraform 配置。
```

**✅ 验证：terraform apply → AWS 控制台看到两个队列：主队列 + DLQ**

---

### 7.3 加上 RDS

🤖 Prompt：

```jsx
现在我想用 Terraform 再创建一个 RDS PostgreSQL 数据库。
用免费套餐 db.t3.micro，数据库名 careplan。

请告诉我需要注意什么，然后给我 Terraform 配置。
```

**✅ 验证：terraform apply → AWS 控制台看到 RDS 实例状态 Available**

### 7.4 创建 Lambda

我们在 Day 13 写了 3 个 Lambda，现在用 Terraform 创建它们：

| Lambda | 做什么 | 谁触发它 |
| --- | --- | --- |
| create_order | 验证输入、存数据库、发 SQS | API Gateway |
| generate_careplan | 调 LLM 生成 CarePlan、更新数据库 | SQS |
| get_order | 查数据库、返回结果 | API Gateway |

🤖 Prompt：

```jsx
我想用 Terraform 创建这 3 个 Lambda 函数：
- create_order：创建订单
- generate_careplan：生成 CarePlan
- get_order：查询订单

以及它们需要的 IAM 权限。

先只创建 Lambda，不用连接 SQS 和 RDS。
```

**✅ 验证：terraform apply → AWS 控制台看到 3 个 Lambda 函数**

---

### 7.5 把 Lambda 跟 SQS 和 RDS 连起来

🤖 Prompt：

```jsx
我已经用 Terraform 创建了 3 个 Lambda、1 个 SQS、1 个 RDS。
现在它们之间还没有关系。

我需要：
- 创建订单的 Lambda 能往 SQS 发消息
- SQS 能自动触发生成 CarePlan 的 Lambda
- 3 个 Lambda 都能连接 RDS 数据库

请告诉我 Terraform 里怎么配置这些关系。
```

**✅ 验证：terraform apply → 去 SQS 控制台看触发器配好了 → 手动测一下 Lambda 能连数据库**

---

### 7.6 创建 API Gateway

🤖 Prompt：

```jsx
现在我想用 Terraform 创建 API Gateway。
先只创建 API Gateway 本身，不用连 Lambda。
```

**✅ 验证：terraform apply → AWS 控制台看到 API Gateway**

---

### 7.7 把 API Gateway 连到 Lambda

🤖 Prompt：

```jsx
我已经有 API Gateway 和 3 个 Lambda。
现在把它们连起来：
- POST /orders → 创建订单的 Lambda
- GET /orders/{id} → 查询订单的 Lambda

请告诉我 Terraform 里怎么配置。
```

**✅ 验证：terraform apply → 拿到 API URL → Postman 测试 → 完整流程跑通**

---

节奏就是：**创建 → 确认存在 → 连接 → 确认能通 → 下一个。** 每一步只做一件事。

---

## 8 面试考点

**Q: 什么是 Infrastructure as Code？**

```jsx
A: 用代码定义基础设施，而不是手动在控制台点。
   配置文件可以放 Git，有版本记录，可以重复使用。
```

---

## ⚠️ 费用提醒

**练习完记得：**

`terraform destroy

一键删除所有资源，不会持续扣费。`

---

## Day 15 完成！

✅ 理解了 Infrastructure as Code

✅ 用 Terraform 一键部署了 AWS 资源

✅ 配置文件放到了 Git

## 课程完成！🎉

**你现在有了一个完整的系统：**

```jsx
功能：
  ✅ 用户提交患者信息
  ✅ 自动检测重复
  ✅ LLM 生成 CarePlan
  ✅ 用户查询结果

技术栈：
  ✅ 本地：Django + Celery + Redis + PostgreSQL
  ✅ AWS：API Gateway + Lambda + SQS + RDS
  ✅ Terraform 一键部署
  ✅ Prometheus + Grafana 监控（本地）
  ✅ CloudWatch 监控（AWS）

面试能说：
  ✅ 为什么用异步处理
  ✅ 为什么用 Lambda + SQS
  ✅ SQS 和 Redis 的区别
  ✅ 什么是 Infrastructure as Code
  ✅ 为什么用 Terraform
```

---

# Day 16 后端程序员每天在干啥：写api

关于工作后你会做什么：

对于 Intern 和 New Grad 来说，工作中最核心的技能就是写 RESTful API。架构设计一般是 Senior 给你的，不会让你自己去设计。前面那些异步、消息队列、AWS、Terraform，其实是出于招聘 JD 的要求，以及让你对整体架构有一个理解，面试的时候说着不慌而已。但 RESTful API 是你真正需要自己理解、自己动手的地方。所以课程最后我准备了一系列 API 练习题，从简单到复杂。前面几个你可能还需要 AI 帮你一步步引导，到最后五个的时候，希望你可以独立完成。

以下的内容可以分成两天做

[API练习](https://www.notion.so/API-2fc73b2e0063800e9cadce28e97997d6?pvs=21)

# 总结：面试准备清单

## 你应该能回答的问题

### 需求分析

- [ ]  “拿到需求后你第一步做什么？” → 和客户确认澄清问题
- [ ]  “你会问客户哪些问题？” → 重复检测逻辑、ERROR vs WARNING 的处理方式

### 架构设计

- [ ]  “为什么用异步处理？” → API 快速响应（~200ms），用户体验好
- [ ]  “如果 LLM 调用失败怎么办？” → 自动重试 + 手动重新生成
- [ ]  “什么是Adapter？” → 隔离外部数据格式的混乱，保护内部数据模型的整洁

### API 设计

- [ ]  “为什么 WARNING 用 409 而不是 400？” → 区分格式错误和业务冲突

### 测试

- [ ]  “怎么测试 LLM 调用？” → Mock

---

## 技术是怎么引入的

| 技术 | 遇到的问题 | 解决方案 |
| --- | --- | --- |
| 消息队列 | 用户不能等 20 秒 | 先返回，后台处理 |
| Celery | 自己写任务处理太麻烦 | 用现成框架 |
| Adapter | 不同数据源格式不统一 | 定义内部标准，适配器转换 |
| Mock | 测试不能真调 LLM | 假装调用了 |
| Docker | 本地能跑服务器挂 | 打包环境 |
| SQS + Lambda | Worker 空闲浪费钱 | 按调用付费 |
| Prometheus | 不知道系统是否正常 | 监控指标 |